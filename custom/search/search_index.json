{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Jam-in-a-Box for Business Automation &amp; Digital Labor","text":""},{"location":"#quick-start","title":"Quick Start","text":"<ol> <li>Select the lab(s) you are interested in in the left column of the table of the Labs to Environments Mapping section</li> <li>Follow the instructions in the right column of the table to request the appropriate environment</li> </ol>"},{"location":"#introduction","title":"Introduction","text":"<p>The Client Onboarding scenario is an end-to-end demo for Cloud Pak for Business Automation (CP4BA) and selected aspects of watsonX Orchestrate (wxO). </p> <p>The CP4BA part covers the following components: Automation Decision Services (ADS), Automation Document Processing (ADP), Business Automation Applications (BAA), Workflow, Content, Robotic Process Automation (RPA), Business Automation Insights (BAI). The wxO part covers skill, skill flow, and automation building.</p> <p>Labs for each capability provide an easy way to gain familiarity with the development aspects to build the respective parts of the Client Onboarding solution.</p> <p>The Jam-in-a-Box environments provide the ability to demo the out-of-box end-to-end Client Onboarding solution and more, run your own mini-Tech Jam, or get self-educated on Business Automation and watsonX Orchestrate as part of Digital Labor.</p> <p>Jam-in-a-Box removes hurdles to Business Automation and Digital Labor adoption through easing availability and sharing of technical enablement. Towards this it offers a set of self-provisionable environments hosted on IBM TechZone, combined with a set of hands-on technical labs spanning all capabilities of Business Automation and watsonX Orchestrate (for watsonX Orchestrate a separate wxO SaaS instance is required).</p>"},{"location":"#use-cases-for-jam-in-a-box","title":"Use Cases for Jam-in-a-Box","text":""},{"location":"#1-technical-enablement","title":"1. Technical Enablement","text":"<ol> <li>Self-enablement - use the environments to gain hands-on experience on one or all capabilities of Business Automation and Digital Labor using a realistic business scenario</li> <li>Client-enablement - use the environments to host a mini-Tech Jam for your clients</li> </ol>"},{"location":"#2-demopox","title":"2. Demo/PoX","text":"<ol> <li>Demo - use the out-of-box Client Onboarding solution and more to present a live demo of Business Automation and Digital Labor capabilities</li> <li>PoX - use the environments as a base to customize/extend the business scenario based on your client\u2019s needs</li> </ol>"},{"location":"#labs-to-environments-mapping","title":"Labs to Environments Mapping","text":"<p>Most labs are accessible using a single Jam-in-a-Box environment. For some labs, you will need a separate environment. The table below provides the respective details:</p> Lab(s) Environment (IBM TechZone - Business Partners and IBMers only) IBM Cloud Pak for Business Automation (End-to-End) -IBM Business Automation Application -IBM Automation Decision Services -IBM Automation Document Processing-IBM Business Automation Insights-IBM Business Automation Workflow-IBM FileNet Content Services (CPE, GraphQL &amp; Navigator) See section Environment Selection for Core Labs below IBM watsonx Orchestrate Pre-deployed Client Onboarding from TechZone based on Apollo Business Automation CP4BA Demo Remarks:- Access to a watsonx Orchestrate SaaS instance is required as an additional prerequisite. Please check the watsonx Orchestrate content on Seismic to learn how to get access to such an instance.- The Jam-in-a-Box environment above can currently only be accessed from the bastion host of the environment. Therefore, it does not support the watsonX Orchestrate lab yet. IBM Process Mining One environment required per user in case of mini-Tech Jams!Please reserve a TechZone Process Mining Environment here. Make sure to select the IBM Process Mining 1.14.3 with Task Mining and ETL - US East only. IBM Robotic Process Automation One environment required per user in case of mini-Tech Jams!Follow the instructions provided on the respective lab overview page IBM CP4BA - Bring-up (Deployment of CP4BA) One environment required per user in case of mini-Tech Jams!Follow the instructions provided on the respective lab overview page <p>[!NOTE]</p> <p>The options mentioned for the first two rows are focused on TechZone environments with pre-deployed Client Onboarding assets. If you have your own CP4BA environment (from TechZone or not), into which you want to deploy the Client Onboarding assets yourself, please refer to this document for details.</p>"},{"location":"#environment-selection-for-core-labs","title":"Environment Selection for Core Labs","text":"<ul> <li> <p>Single-user/self-paced Client Onboarding demo and labs on CP4BA 23.0.2</p> <ul> <li>Pre-deployed Client Onboarding from TechZone<ul> <li>Benefits: Provisioning time only 2-3 hours; Support of ADP lab</li> <li>Limitations: Need to use RDP to connect to bastion host to perform demo/labs; No support for RPA as part of Client Onboarding demo; No support for watsonX Orchestrate lab (all three to be lifted)</li> </ul> </li> <li>Pre-deployed Client Onboarding from TechZone based on Apollo Business Automation CP4BA Demos<ul> <li>Benefits: Accessible from any web browser; Supports watsonX Orchestrate lab; Supports ADP lab</li> <li>Limitations: Provisioning time 5-7 hours; No support for RPA as part of Client Onboarding demo</li> </ul> </li> </ul> </li> <li> <p>Workshop/Mini-Tech Jam with 10-20 participants on CP4BA 23.0.2</p> <ul> <li>Pre-deployed Client Onboarding from TechZone (coming soon)<ul> <li>Benefits: Provisioning time only 2-3 hours; Comes with 20 users for mini-Tech Jams; Accessible from any web browser; Supports watsonX Orchestrate lab; Can be configured to use RPA as part of Client Onboarding demo</li> <li>Limitations: No support for ADP lab (due to ADP design limitations)</li> </ul> </li> <li>Pre-deployed Client Onboarding from TechZone based on Apollo Business Automation CP4BA Demos<ul> <li>Benefits: Comes with 20 users for mini-Tech Jams; Accessible from any web browser; Supports watsonX Orchestrate lab</li> <li>Limitations: Provisioning time 5-7 hours; No support for RPA as part of Client Onboarding demo; No support for ADP lab as part of mini-Tech Jam (due to ADP design limitations)</li> </ul> </li> </ul> </li> </ul>"},{"location":"#support","title":"Support","text":"<p>We aim to support successfully utilizing our Jam-in-a-Box.</p> <p>Business Partners and IBMers</p> <p>To engage us, drop us a message at #jam-in-a-box-ba-dl.</p> <p>All others</p> <p>For anyone who doesn\u2019t fall into the business partner or IBM employee category, please feel free to open a new issue on our GitHub repository. We\u2019ll be more than happy to address your questions and concerns there.</p>"},{"location":"#disclaimer","title":"Disclaimer","text":"<p>The information, tools, and artifacts describes and linked are provided AS-IS and without any warranty. Please also refer to the license that is part of this repository for details.</p>"},{"location":"README_other/","title":"Jam-in-a-Box for Business Automation - Other Environments","text":""},{"location":"README_other/#quick-start","title":"Quick Start","text":"<ol> <li>Select the solution and version of the asset of interest from the Solutions and Assets section</li> <li>Follow the instructions in the Quick Start section of the linked document</li> </ol>"},{"location":"README_other/#introduction","title":"Introduction","text":"<p>The Solutions and Assets section below lists the available assets that can be imported into an existing Cloud Pak for Business Automation (CP4BA) environment.</p> <p>In case you don't have an existing CP4BA environment, please follow these instruction on how to request an environment that is pre-deployed and pre-configured with the Client Onboarding solution.</p>"},{"location":"README_other/#solutions-and-assets","title":"Solutions and Assets","text":""},{"location":"README_other/#client-onboarding","title":"Client Onboarding","text":"<p>The Client Onboarding scenario is an end-to-end demo for Cloud Pak for Business Automation that covers the following components: Automation Decision Services, Automation Document Processing, Workflow, Content, Robotic Process Automation, Business Automation Insights.</p> <p>More information on the assets, how to reserve an environment and the labs are listed below for the versions of CP4BA that are currently supported (versions not mentioned are not or no longer supported!)</p> <ul> <li>CP4BA 23.0.2</li> <li>CP4BA 23.0.1 - Deprecated</li> </ul>"},{"location":"README_other/#email-server-and-web-based-email-client","title":"Email Server and Web-based Email Client","text":"<p>It can be useful to have an email server and client locally deployed within a Cloud Pak for Business Automation instance. While this email server can only handle emails locally, other CP4BA capabilities can be connected to it, e.g. to send notifications. In that way the CP4BA instance is self-contained without external dependencies.</p> <p>Follow these instructions to deploy such a setup into a CP4BA 22.0.2, 23.0.1, or 23.0.2 Starter deployment environment. It will also also you to add additional users to the CP4BA environment which can be useful for demos.</p>"},{"location":"README_other/#support","title":"Support","text":"<p>We aim to support successfully utilizing our Jam-in-a-Box.</p> <p>Business Partners and IBMers</p> <p>To engage us, drop us a message at #jam-in-a-box-ba-dl.</p> <p>All others</p> <p>Open a new issue in this GitHub</p>"},{"location":"README_other/#disclaimer","title":"Disclaimer","text":"<p>The information, tools, and artifacts describes and linked are provided AS-IS and without any warranty. Please also refer to the license that is part of this repository for details.</p>"},{"location":"Archive/JamInABox2201/","title":"- No longer supported nor working! -","text":""},{"location":"Archive/JamInABox2201/#jam-in-a-box-for-business-automation-for-cp4ba-2201","title":"Jam-in-a-Box for Business Automation (for CP4BA 22.0.1)","text":""},{"location":"Archive/JamInABox2201/#introduction","title":"Introduction","text":"<p>Use the Jam-in-a-Box environments to demo the out-of-box end-to-end Client Onboarding solution, run your own mini-Tech Jam, or get self-educated on Business Automation.</p> <p>Jam-in-a-Box removes hurdles to Business Automation adoption through easing availability and sharing of technical enablement. Towards this it offers a set of self-provisionable environments hosted on IBM TechZone, combined with a set of hands-on technical labs spanning all capabilities of Business Automation.</p>"},{"location":"Archive/JamInABox2201/#use-cases-for-jam-in-a-box","title":"Use cases for Jam-in-a-Box","text":""},{"location":"Archive/JamInABox2201/#1-technical-enablement","title":"1. Technical Enablement","text":"<ol> <li>Self-enablement - use the environment to gain hands-on experience on one or all capabilities of Business Automation using a realistic business scenario</li> <li>Client-enablement - use the environment to host a mini-Tech-Jam for your clients</li> </ol>"},{"location":"Archive/JamInABox2201/#2-demopox","title":"2. Demo/PoX","text":"<ol> <li>Demo - use out-of-box Client Onboarding to present a live demo of Business Automation capabilities</li> <li>PoX - use the environments as a base to customize/extend the business scenario based on your client\u2019s needs</li> </ol>"},{"location":"Archive/JamInABox2201/#table-of-content","title":"Table of Content","text":"<ul> <li> <p>Software</p> </li> <li> <p>Infrastructure from TechZone (different labs use different environments, for details see below)</p> <ul> <li>Managed Red Hat OpenShift (OCP 4.10) on IBM Cloud</li> <li>IBM Cloud Pak for Business Automation 22.0.1 IF005</li> <li>IBM Process Mining 1.13.2</li> <li>IBM Robotic Process Automation 23.0.2</li> </ul> </li> <li> <p>Solution (import required for one environment, for details see below)</p> <ul> <li>Client Onboarding solution       (covering Automation Decision Services, Automation Document Processing, Workflow, Content, Robotic Process Automation, Business Automation Insights)</li> </ul> </li> <li> <p>Assets</p> </li> <li> <p>Nine hands-on labs</p> <p>Mapping of labs to environments</p> Lab(s) Environment (IBM TechZone - Business Partners and IBMers only) IBM Cloud Pak for Business Automation (End-to-End)IBM Business Automation ApplicationIBM Business Automation InsightsIBM FileNet Content Services (use these special lab instructions)IBM Automation Decision ServicesIBM Business Automation Workflow Jam-in-a-box on CP4BA - V22.0.1 on Red Hat OpenShift on IBM Cloud (in case of client-facing activity)After successfully provisioning the environmentfollow the instructions to deploy the Client Onboarding scenario(Also see instructions in case you don't have access to/can't get a IBM TechZone environment) IBM CP4BA - Bring-up Lab Follow the instructions provided on the respective lab overview page IBM Process Mining Follow the instructions provided on the respective lab overview page IBM Robotic Process Automation Follow the instructions provided on the respective lab overview page </li> <li> <p>All artifacts for the Client Onboarding scenario including deployment automation to quickly and easily deploy them</p> </li> </ul>"},{"location":"Archive/JamInABox2201/#support","title":"Support","text":"<p>We aim to support successfully utilizing our Jam-in-a-Box.</p> <p>Business Partners and IBMers To engage us, drop us a message at #jam-in-a-box-business-automation.</p> <p>All others Open a new issue in this GitHub</p>"},{"location":"Archive/JamInABox2201/#disclaimer","title":"Disclaimer","text":"<p>The information, tools, and artifacts describes and linked are provided AS-IS and without any warranty. Please also refer to the license that is part of this repository for details.</p>"},{"location":"Bring-up/","title":"IBM CP4BA - Bring-up Lab","text":""},{"location":"Bring-up/#overview","title":"Overview","text":"<p>Install and configure a Production deployment of IBM Cloud Pak for Business Automation (CP4BA, version 23.0.2 IF002) on a RedHat OpenShift cluster from TechZone using the CP4BA rapid deployment scripts, or the product scripts.</p> <p>Track 3 - Administrator Role</p> <p>Note: Labs as documented here only require an environment created from TechZone. It requires to be separately created, see the Lab Guides for all needed details. You also need a CP4BA License which will get accessed from the IBM Container Library, see also the Lab Guide for all needed details.</p> <p>If you like to bring-up your own CP4BA instance independently of a Tech Jam, simply follow the instructions in our CP4BA rapid deployment project</p>"},{"location":"Bring-up/#bring-up-lab-1","title":"Bring-up Lab #1:","text":"<p>Learn how to quickly bring-up a Production deployment of IBM CP4BA using the rapid deployment scripts. Click here to get to the Lab Guide.</p> <p>Note: Complete this Lab to earn a Badge.</p> <p>Approximate Lab Duration: 6 hours</p>"},{"location":"Bring-up/#bring-up-lab-2","title":"Bring-up Lab #2:","text":"<p>Learn how to quickly bring-up a Production deployment of IBM CP4BA using the product scripts. Click here to get to the Lab Guide.</p> <p>Note: No Badge available yet for this Lab.</p> <p>Approximate Lab Duration: 8 hours</p>"},{"location":"Bring-up/Bring-Up-Lab-1/","title":"Bring-up Lab - Lab 1 \u2013 Using Rapid Deployment Scripts","text":"<p>Version 1.0</p>"},{"location":"Bring-up/Bring-Up-Lab-1/#authors","title":"Authors","text":"<ul> <li>Thomas Schulze - ThomasSchulze@de.ibm.com</li> <li>Matthias Jung - matthias.jung@de.ibm.com</li> <li>Jorge D. Rodriguez - jorgedr@us.ibm.com</li> <li>Zhong Tao Gao - gaozt@cn.ibm.com</li> </ul>"},{"location":"Bring-up/Bring-Up-Lab-1/#introduction","title":"Introduction","text":""},{"location":"Bring-up/Bring-Up-Lab-1/#ibm-cloud-pak-for-business-automation","title":"IBM Cloud Pak for Business Automation","text":"<p>IBM Cloud Pak for Business Automation (CP4BA) assembles certified software from the IBM Automation Platform for Digital Business on multiple cloud infrastructures. It offers design, build, run, and automation services to rapidly scale your programs and fully execute and operationalize an automation strategy.</p> <p>You can read more about CP4BA here</p>"},{"location":"Bring-up/Bring-Up-Lab-1/#lab-overview","title":"Lab Overview","text":"<p>In this Lab, you will learn how to configure and install a CP4BA production deployment on an OpenShift cluster using the rapid deployment scripts developed by the IBM Business Automation and Digital Labor SWAT team.</p> <p>The rapid deployment scripts cover a small area of deployments, and are thus the preferred choice for rapid deployment of PoC or Demo environments. They are available on this public GitHub and, therefore, can be used by customers, business partners, and IBMers.</p> <p>The rapid deployment scripts are available for some selected CP4BA versions.</p> <p>As part of this Lab, you will only deploy DB2 and CP4BA. All other required preparation steps (OpenShift, LDAP, storage, preparation of bastion host, ...) were already completed on the provided environment, so you can concentrate on the essential part: Configure and Install IBM Cloud Pak for Business Automation version 23.0.2 on Red Hat OpenShift.</p> <p>We have created a TechZone environment preconfigured with a bastion host and a three-worker node Red Hat OpenShift cluster. In addition, IBM Security Directory Server (SDS) was installed and configured on the bastion host required by CP4BA. To fit the size of the OpenShift cluster, it is recommended to use our FoundationContent template for use by the rapid deployment scripts. This template will install foundational services required by CP4BA and Filenet Content Manager components.</p> <p>Using other templates that would deploy more CP4BA components is very similar, but would require more system resources for building such a larger deployment, that are not available on the provided TechZone environment.</p> <p>During the first exercise, you will reserve an environment on TechZone, access it, and verify that your RedHat OpenShift cluster is working correctly.</p> <p>The following exercises will guide you through configuring and installing DB2 containerized and CP4BA version 23.0.2 IF002 on OCP using the rapid deployment scripts.</p> <p>Complete this Lab to be able to earn a badge.</p>"},{"location":"Bring-up/Bring-Up-Lab-1/#notation","title":"Notation","text":"<p>Paragraphs formatted like the below contain excerpts from configuration files, or commands to enter in a Terminal window. The paragraph can be copied to the clipboard by using an icon available on the right edge of the grey area.</p> <pre><code>whoami\n</code></pre> <p>Paragraphs like the below contain additional information, which would help to understand further concepts. While it is not needed to read them, if the only wish is to follow the guide to get a CP4BA environment running, the information in those sections might also be used on badge questions.</p> <p>The above command shows the name of the user, who was used to logon to the operation system. While you typically know who you are, and might not need it, this command is often used in shellscripts.</p> <p>Approximate Duration: 6 hours</p>"},{"location":"Bring-up/Bring-Up-Lab-1/#table-of-exercises","title":"Table of Exercises","text":"<ul> <li>Exercise 1: Prepare yourself for this Bring-Up Lab</li> </ul> <p>Guides you through reserving of the Lab Environment, customization of the Bastion node, and consistency checking of the Openshift environment.</p> <ul> <li>Exercise 2: Deploy DB2</li> </ul> <p>In this exercise you will deploy DB2 operator and a DB2 instance on your OpenShift environment using the rapid deployment scripts.</p> <ul> <li>Exercise 3: Create DB2 Databases</li> </ul> <p>See how easy it is to create the needed databases using the rapid deployment scripts.</p> <ul> <li>Exercise 4: Deploy CP4BA Operator</li> </ul> <p>The Case Package is downloaded, and the clusteradmin setup script is used to deploy the CP4BA Operators. Required preconditions are verified.</p> <ul> <li>Exercise 5: Deploy CP4BA</li> </ul> <p>Last but not least, let's deploy a CP4BA instance.</p> <ul> <li>Once you completed all these exercises, you can do the Quiz to earn a Badge.</li> </ul>"},{"location":"Bring-up/Bring-Up-Lab-1/#notices","title":"Notices","text":"<p>This information was developed for products and services offered in the USA.</p> <p>IBM may not offer the products, services, or features discussed in this document in other countries. Consult your local IBM representative for information on the products and services currently available in your area. Any reference to an IBM product, program, or service is not intended to state or imply that only that IBM product, program, or service may be used. Any functionally equivalent product, program, or service that does not infringe any IBM intellectual property right may be used instead. However, it is the user's responsibility to evaluate and verify the operation of any non-IBM product, program, or service.</p> <p>IBM may have patents or pending patent applications covering subject matter described in this document. The furnishing of this document does not grant you any license to these patents. You can send license inquiries, in writing, to:</p> <p>IBM Director of Licensing IBM Corporation North Castle Drive, MD-NC119 Armonk, NY 10504-1785 United States of America  </p> <p>The following paragraph does not apply to the United Kingdom or any other country where such provisions are inconsistent with local law: INTERNATIONAL BUSINESS MACHINES CORPORATION PROVIDES THIS PUBLICATION \"AS IS\" WITHOUT WARRANTY OF ANY KIND, EITHER EXPRESS OR IMPLIED, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF NON-INFRINGEMENT, MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE. Some states do not allow disclaimer of express or implied warranties in certain transactions, therefore, this statement may not apply to you.</p> <p>This information could include technical inaccuracies or typographical errors. Changes are periodically made to the information herein; these changes will be incorporated in new editions of the publication. IBM may make improvements and/or changes in the product(s) and/or the program(s) described in this publication at any time without notice. </p> <p>Any references in this information to non-IBM websites are provided for convenience only and do not in any manner serve as an endorsement of those websites. The materials at those websites are not part of the materials for this IBM product and use of those websites is at your own risk.</p> <p>IBM may use or distribute any of the information you supply in any way it believes appropriate without incurring any obligation to you.</p> <p>Information concerning non-IBM products was obtained from the suppliers of those products, their published announcements or other publicly available sources. IBM has not tested those products and cannot confirm the accuracy of performance, compatibility or any other claims related to non-IBM products. Questions on the capabilities of non-IBM products should be addressed to the suppliers of those products.</p> <p>This information contains examples of data and reports used in daily business operations. To illustrate them as completely as possible, the examples include the names of individuals, companies, brands, and products. All of these names are fictitious and any similarity to the names and addresses used by an actual business enterprise is entirely coincidental.</p>"},{"location":"Bring-up/Bring-Up-Lab-1/#trademarks","title":"Trademarks","text":"<ul> <li> <p>IBM, the IBM logo, and ibm.com are trademarks or registered trademarks of International Business Machines Corp., registered in many jurisdictions worldwide. Other product and service names might be trademarks of IBM or other companies. A current list of IBM trademarks is available on the web at \u201cCopyright and trademark information\u201d at www.ibm.com/legal/copytrade.shtml.</p> </li> <li> <p>Adobe, the Adobe logo, PostScript, and the PostScript logo are either registered trademarks or trademarks of Adobe Systems Incorporated in the United States, and/or other countries. </p> </li> <li> <p>Cell Broadband Engine is a trademark of Sony Computer Entertainment, Inc. in the United States, other countries, or both and is used under license therefrom. </p> </li> <li> <p>Intel, Intel logo, Intel Inside, Intel Inside logo, Intel Centrino, Intel Centrino logo, Celeron, Intel Xeon, Intel SpeedStep, Itanium, and Pentium are trademarks or registered trademarks of Intel Corporation or its subsidiaries in the United States and other countries. </p> </li> <li> <p>IT Infrastructure Library is a Registered Trade Mark of AXELOS Limited. </p> </li> <li> <p>ITIL is a Registered Trade Mark of AXELOS Limited. </p> </li> <li> <p>Java and all Java-based trademarks and logos are trademarks or registered trademarks of Oracle and/or its affiliates. </p> </li> <li> <p>Linear Tape-Open, LTO, the LTO Logo, Ultrium, and the Ultrium logo are trademarks of HP, IBM Corp. and Quantum in the U.S. and other countries. </p> </li> <li> <p>Linux is a registered trademark of Linus Torvalds in the United States, other countries, or both. </p> </li> <li> <p>Microsoft, Windows, Windows NT, and the Windows logo are trademarks of Microsoft Corporation in the United States, other countries, or both. </p> </li> <li> <p>UNIX is a registered trademark of The Open Group in the United States and other countries.</p> </li> </ul> <p>\u00a9 Copyright International Business Machines Corporation 2024. </p> <p>This document may not be reproduced in whole or in part without the prior written permission of IBM. US Government Users Restricted Rights - Use, duplication or disclosure restricted by GSA ADP Schedule Contract with IBM Corp.</p>"},{"location":"Bring-up/Bring-Up-Lab-1/Exercise-1-Prepare/","title":"Exercise 1: Prepare yourself for this Bring-Up Lab","text":""},{"location":"Bring-up/Bring-Up-Lab-1/Exercise-1-Prepare/#11-introduction","title":"1.1 Introduction","text":"<p>This exercise verifies that you have all prerequisites in place and instructs you how to reserve your lab environment. The lab environment consists of a Bastion Host VM and a Red Hat OpenShift Container Platform (OCP) Cluster with three master and three worker VMs.</p>"},{"location":"Bring-up/Bring-Up-Lab-1/Exercise-1-Prepare/#111-bastion-host-vm","title":"1.1.1 Bastion Host VM","text":"<p>A bastion host is a computer from which you access the OpenShift cluster through the command line to administrate the OCP cluster. Administration of an OCP cluster also includes the configuration and installation of new software such as CP4BA. To do that, this Lab shows you how to use the scripts and information provided by the CP4BA development teams, by executing these scripts on the bastion host. Therefore, the bastion host must be one of RHEL, CentOS, or macOS. Finally, all commands these scripts need must also be available on the bastion host, for example, the OpenShift CLI, Kubernetes CLI, and so on.</p> <p>The preparation of a bastion host is discussed in the documentation on this page: Preparing a client to connect to the cluster.</p> <p>Other services are also deployed on this specific bastion host. The most important ones are the LDAP Server, which is used as the Authentication provider for the CP4BA deployment, and an NFS Server to provide persistent storage capabilities to the Openshift cluster.</p>"},{"location":"Bring-up/Bring-Up-Lab-1/Exercise-1-Prepare/#112-red-hat-openshift-container-platform-ocp-cluster-vms","title":"1.1.2 Red Hat OpenShift Container Platform (OCP) Cluster VMs","text":"<p>The OpenShift cluster was configured using OCP version 4.12.53. It will host the DB2 and CP4BA containers which you will install later in this Lab. You can access your OCP cluster from the bastion host either by command line (oc command) or the OpenShift Web Console by Browser. In addition, a storage class supporting mode read/write many (RWX), that is required by CP4BA, is already available on the cluster.</p>"},{"location":"Bring-up/Bring-Up-Lab-1/Exercise-1-Prepare/#12-exercise-instructions","title":"1.2 Exercise Instructions","text":"<p>Before you can start this Lab, you need the following prerequisites: - an entitlement key, and - an environment with a bastion host and OpenShift cluster from TechZone.</p> <p>All the tools such as podman and OpenShift command-line interface needed while the lab are already available on the provided bastion host.</p>"},{"location":"Bring-up/Bring-Up-Lab-1/Exercise-1-Prepare/#121-get-the-entitlement-key","title":"1.2.1 Get the Entitlement Key","text":"<p>To complete this Lab, you must have an entitlement key with access to pull CP4BA images from the IBM Container Software Library cp.icr.io.</p> <ol> <li> <p>Check that you have an entitlement key with the proper image access. For this, please open IBM Container Library and log in with your IBM ID. IBMers can use their w3 ID.</p> </li> <li> <p>Then, switch to the Container software library page. IBMers and some Business Partners will see the following, which means that they do have such an entitlement key available:</p> </li> </ol> <p></p> <p>Business Partners that do not see all here, before proceeding, must verify that CP4BA is listed on the Container software library page.    If you don\u2019t see a CP4BA license listed, you cannot perform this bring-up Lab.</p>"},{"location":"Bring-up/Bring-Up-Lab-1/Exercise-1-Prepare/#122-reserve-the-openshift-tech-zone-envrioment","title":"1.2.2 Reserve the OpenShift Tech Zone Envrioment","text":"<ol> <li> <p>To get an OpenShift cluster from TechZone, access IBM Technology Zone: https://techzone.ibm.com/</p> </li> <li> <p>To sign-in, either use your IBM ID or your company credentials if SSO is set up between your company and IBM. For example, if you have an IBM W3 or IBM Partnerworld ID, you should use this ID.</p> </li> </ol> <p>Dependent on the IBM ID used to sign in, you may or may not be able to reserve an OpenShift cluster. If you can't reserve a cluster with the current IBM ID, check if you have another IBM ID that is enabled for IBM Technology Zone reservations.</p> <ol> <li> <p>Once signed in, open the lab resource page: https://techzone.ibm.com/collection/ibm-cloud-pak-for-business-automation-demos-and-labs-bring-up-lab</p> </li> <li> <p>On the left hand side select the Environments tab. There you should find environment CP4BA Bring-Up Lab Environment v1.0, for that environment click on Reserve.</p> </li> </ol> <p></p> <p>If you don't see the tile, go back to step 1 and sign in with a different ID.</p> <ol> <li>Select Reserve now.</li> </ol> <p></p> <ol> <li>On the next page, provide the necessary information: Provide the Purpose, e.g., \"Practice / Self-Education\", a description, select the geography closest to your location and select the end time and date for the reservation. Plan for at least 6 hours, maybe more. Then click Submit.</li> </ol> <p></p> <p></p> <p></p> <ol> <li>After you click Submit, you'll get some emails from IBM Technology Zone. Provisioning the environment will take about one hour, then you should get a second email informing you that your environment is Ready.</li> </ol> <p></p> <p>In case there was an issue provisioning the environment, delete the reservation and try again later.</p> <p>Once you get the email informing you that your environment is Ready, you can start your Lab.</p>"},{"location":"Bring-up/Bring-Up-Lab-1/Exercise-1-Prepare/#123-access-the-openshift-tech-zone-envrioment","title":"1.2.3 Access the OpenShift Tech Zone Envrioment","text":"<ol> <li> <p>On your local machine, open the  TechZone My reservations page. In the browser window, select the reservation for the Bring Up lab.</p> </li> <li> <p>Scroll down to the VM Remote Console section at the bottom. Click on the bastion VM. This will open the desktop of the bastion host in the Browser.</p> </li> </ol> <p></p> <ol> <li>If you see the current time and date, press the Space key. Log-in to the desktop of the bastion host using cp4badmin / passw0rd (where the third-last character is a zero).</li> </ol> <p></p> <p>Note: If the screen is blank, move the mouse.</p> <p>Now that you have your demo and lab environment available learn how to work with your environment before you start with the Lab.</p> <ol> <li> <p>Once you logged in, you see the Red Hat Enterprise Linux (RHEL) Server desktop of your bastion host.</p> </li> <li> <p>Next, ensure the VM is connected to the network before proceeding. Check that the network icon in the top right corner shows connected. The environment is not usable if the VM is not correctly connected to the network.</p> </li> </ol> <p>Connected:  (if not connected that icon will not be shown)</p> <ol> <li>Change the size and resolution of the desktop to your liking. Open Applications \u2192 System Tools \u2192 Settings. The Displays page already opens. Change the Resolution to your liking.</li> </ol> <p></p> <p>In addition, you can switch to Full screen mode. Before you do that, open these lab instructions in Firefox browser (shortcut on the desktop) of the bastion host. Within the bastion host, open Firefox, and click the Tech Jam Labs bookmark. This brings you to an older github, but the link to the moved one is available on that page. Click here. That now brings you to the ba-dl-tech-jam github, from there open the Labs.md page and navigate to these lab instructions from within the bastion host. Once you have the lab instructions open there, you can switch to Full screen mode:</p> <p></p> <ol> <li>To access your OpenShift cluster through a Browser, open another tab in Firefox. Open bookmark OpenShift Web Console</li> </ol> <p>Note: In case you get the Warning: Potential Security Risk Ahead, click Advanced\u2026 and then click Accept the Risk and Continue. This is needed two times to finally get to the OCP log-in screen.</p> <ol> <li> <p>Log in with ocpadmin / passw0rd (where the third-last character is a zero).</p> </li> <li> <p>Once logged in, verify that the OpenShift Web Console opens and that you have Administrator access.</p> </li> </ol> <p></p> <ol> <li> <p>Next, in the OCP Web Console on the left hand side, expand Compute and select MachineConfigPools. For both entries, resume the updates.</p> <p></p> </li> <li> <p>On the left hand side, go back to Home -&gt; Overview. Check that the Status of Cluster, Control Plane and Operators is green, that should happen automatically after a while.</p> <p></p> </li> <li> <p>Still on the Overview page, the main page, scroll down and verify that the Cluster inventory shows no errors.</p> <p></p> <p>Note: The number of pods shown here could be different to what you will see. For Pods, you might see pods in error and / or in progressing state.</p> <p>The progressing pods should disappear automatically after a while.</p> </li> <li> <p>To get rid of the pods in error click on the red icon behind Pods. You\u2019ll now see a list of pods that are in error.</p> <p>For each pod in error, click the three dots at the end of the row and delete that pod.</p> </li> <li> <p>In case of errors, warnings, or pending indicators that you can't resolve, reach out to your hosting staff to get help.</p> </li> <li> <p>To log in through the oc command line interface, expand ocpadmin in the top right corner and select Copy login command.</p> <p></p> </li> <li> <p>A new tab opens. Log in again with ocpadmin / passw0rd (where the third-last character is a zero) and click Display Token.</p> </li> <li> <p>Copy the entire oc login command to the clipboard.</p> <p></p> </li> <li> <p>Open a Terminal window, paste the clipboard's content, and hit Enter.</p> <p></p> </li> <li> <p>Finally, run this command:</p> </li> </ol> <pre><code>oc version\n</code></pre> <pre><code>Expected output, make sure to see the `Server Version:` line:\n\n![oc version output](images/1.2.3-oc-version.png)\n</code></pre> <p>You have now successfully accessed and updated your environment and are ready to start with the lab.</p> <p>To continue, refer to Exercise 2: Deploy DB2.</p>"},{"location":"Bring-up/Bring-Up-Lab-1/Exercise-2-Deploy-DB2/","title":"Exercise 2: Deploy DB2","text":""},{"location":"Bring-up/Bring-Up-Lab-1/Exercise-2-Deploy-DB2/#21-introduction","title":"2.1 Introduction","text":"<p>A CP4BA production mode deployment requires you to provide the databases needed by the CP4BA components. In this exercise, you'll first deploy the DB2 Operator and containers on the OpenShift cluster. Other databases are also supported, for example, Oracle, SQL Server, or PostgreSQL. See Detailed system requirements: https://www.ibm.com/docs/en/cloud-paks/cp-biz-automation/23.0.2?topic=pcmppd-system-requirements</p> <p>The database can run on OpenShift, but CP4BA also supports on-premises installations. We will be using OpenShfit to install the database.</p> <p>In this exercise, you will run scripts to install DB2 Operator, and run the Operator to create a DB2 instance.</p>"},{"location":"Bring-up/Bring-Up-Lab-1/Exercise-2-Deploy-DB2/#22-exercise-instructions","title":"2.2 Exercise Instructions","text":"<ol> <li>On your bastion host use the Terminal to switch to a directory prepared for you to contain the rapid deployment and other scripts.</li> </ol> <pre><code>cd /home/cp4badmin/Desktop/Labfiles\n</code></pre> <ol> <li>Clone the rapid deployment git repository onto your bastion host and copy the deployment scripts.</li> </ol> <p>Note: As part of this doc, we assume you copy the deployment scripts into directory mycluster. If you select a different directory, you must change some of the commands in the steps below; otherwise, you can copy/paste them as is.</p> <pre><code>git clone https://github.com/IBM/cp4ba-rapid-deployment.git\n</code></pre> <pre><code>cd cp4ba-rapid-deployment/cp4ba-23-0-2\n</code></pre> <pre><code>cp -r scripts mycluster\n</code></pre> <pre><code>cd mycluster/deployment-db2-cp4ba\n</code></pre> <p>Sample output of the previous commands:</p> <p></p> <ol> <li>Open the parameters file for DB2, 01-parametersForDb2OnOCP.sh, with gedit.</li> </ol> <pre><code>gedit 01-parametersForDb2OnOCP.sh\n</code></pre> <ol> <li> <p>Apply the following changes:</p> </li> <li> <p>cp4baTemplateToUse \u2013 Name of CP4BA deployment template that will be used</p> <p>set the value to ibm_cp4a_cr_template.002.ent.FoundationContent.yaml</p> <p>Notes:</p> <p>The rapid deployment scripts provide multiple CP4BA templates from which you can choose. For example, this \"FoundationContent\" template deploys the foundation and the content patterns of CP4BA. Other templates deploy different patterns and thus can be used when other components are needed.</p> <p>The ClientOnboardingDemo pattern, for example, also deploys the Application, Decisions_ads, and Workflow patterns and brings with it most components needed to run the Client Onboarding Demo.</p> <p>Due to the available OpenShift cluster size, other templates can't be used for this bring-up Lab. Of course, if you later deploy on your own OCP cluster that provides more CPU and memory, you would also be able to deploy larger templates.</p> <p>The template name is important at this point as it defines the needed databases and the CPU and memory needed for the DB2 container. It also contains a definition of the databases that need to be generated by the scripts.</p> </li> <li> <p>db2OnOcpProjectName \u2013 Project/namespace where DB2 should be installed, for example, ibm-db2 (you could specify any project name here, if that does not exist yet, it will be created by the scripts)</p> <p>set the value to ibm-db2</p> </li> <li> <p>db2AdminUserPassword \u2013 Password that will be assigned to the db2 instance user.</p> <p>set the value to passw0rd (where the third-last character is a zero)</p> </li> <li> <p>db2StandardLicenseKey \u2013 A DB2 Standard License key to assign to DB2 to allow for larger use of CPU and memory</p> <p>remove the default value REQUIRED, and leave this parameter empty</p> <p>Note: The CP4BA template you are deploying as part of this Lab requires three databases. DB2 community edition (installed when you don't specify a DB2 Standard License key) allows for enough CPU and memory for those three databases. Only when selecting a larger CP4BA template, would this key be needed.</p> </li> <li> <p>db2Cpu \u2013 Number of CPUs for DB2 pod according to the selected CP4BA template</p> <p>set the value to 4</p> </li> <li> <p>db2Memory \u2013 Amount of memory for DB2 pod according to the selected CP4BA template</p> <p>set the value to 16Gi</p> </li> <li> <p>The changes you made so far should look as shown below.</p> <p></p> </li> <li> <p>Leave all other parameters at their default values</p> <p>The storage class nfs-client available on your OpenShift cluster from TechZone is already referenced under property db2OnOcpStorageClassName as default value.</p> </li> <li> <p>Finally, save your changes and close the editor.</p> </li> <li> <p>Run script 02-createDb2OnOCP.sh. This script will now install and configure DB2 for you based on the parameters previously specified in 01-parametersForDb2OnOCP.sh.</p> </li> </ol> <pre><code>./02-createDb2OnOCP.sh\n</code></pre> <p>Notes:</p> <p>To successfully run the script, you need the  jq tool and podman installed on your bastion host. For this Lab, these tools are already available on your bastion host.</p> <p>This script will prompt you for various input. Please have a look at the sample script output provided below to see the answers you must use.</p> <p>You need your Entitlement Registry key handy, see also https://myibm.ibm.com/products-services/containerlibrary.</p> <p>When you paste your Entitlement Registry key, it will not be shown; therefore, paste it just once and hit the Enter key.</p> <p>This script will exit if errors are hit during the installation.</p> <p>If you get the error message:</p> <pre><code>error: unable to recognize \"db2OperatorCatalog.yaml\": Unauthorized\n</code></pre> <p>Check whether you have successfully logged on to the OCP cluster on the command line.</p> <p>Sample script output:</p> <pre><code>./02-createDb2OnOCP.sh\n\nFound 01-parametersForDb2OnOCP.sh.  Reading in variables from that script.\n   Reading 01-parametersForDb2OnOCP.sh ...\nDone!\n\nThis script installs Db2u on OCP into project ibm-db2. For this, you need the jq tool installed and your Entitlement Registry key handy.\n\n\nTemplate ibm_cp4a_cr_template.002.ent.FoundationContent.yaml will be used\nThe template requires  1 database instances. Each instance uses 4 cpus and 16Gi memory.\n\nDo you want to continue (Yes/No, default: No): Yes   &lt;--- Enter Yes here\n\nInstalling Db2U on OCP...\n\nInstalling the DB2 Operator Catalog...\ncatalogsource.operators.coreos.com/ibm-db2uoperator-catalog created\n\nCreating project ibm-db2...\nnamespace/ibm-db2 created\nNow using project \"ibm-db2\" on server \"https://api.ocp.ibm.edu:6443\".\n\nCreating secret ibm-registry. For this, your Entitlement Registry key is needed.\n\nYou can get the Entitlement Registry key from here: https://myibm.ibm.com/products-services/containerlibrary\n\nEnter your Entitlement Registry key: &lt;paste your Entitlement Registry key here ONCE, it will not be shown, then hit the Enter key&gt;\nVerifying the Entitlement Registry key...\nLogin Succeeded!\nEntitlement Registry key is valid.\nsecret/ibm-registry created\n\nModifying the OpenShift Global Pull Secret (you need jq tool for that):\nsecret/pull-secret data updated\n\nCreating Operator Group object for DB2 Operator\noperatorgroup.operators.coreos.com/ibm-db2-group created\n\nCreating Subscription object for DB2 Operator\nsubscription.operators.coreos.com/db2u-operator created\n\nWaiting up to 5 minutes for DB2 Operator install plan to be generated.\nMon Apr  1 07:00:00 CDT 2024\n\nApproving DB2 Operator install plan.\ninstallplan.operators.coreos.com/install-ggrgx patched\n\nWaiting up to 5 minutes for DB2 Operator to install.\nMon Apr  1 07:01:00 CDT 2024\n\nDeploying the Db2u cluster.\ndb2ucluster.db2u.databases.ibm.com/db2-inst1 created\n\nWaiting up to 15 minutes for c-db2-inst1-db2u statefulset to be created.\nMon Apr  1 07:02:00 CDT 2024\n\nPatching db2-inst1-db2u statefulset.\nSkipped\n\nWaiting up to 30 minutes for db2-inst1-restore-morph job to complete successfully.\nMon Apr  1 07:03:00 CDT 2024\n\nUpdating number of databases allowed by DB2 installation from 8 to 30.\nconfigmap/c-db2-inst1-db2dbmconfig replaced\n\nUpdating database manager running configuration.\nDB20000I  The UPDATE DATABASE MANAGER CONFIGURATION command completed \nsuccessfully.\n\nRestarting DB2 instance.\nWolverine HA management state was disabled successfully.\n04/01/2024 07:04:00     0   0   SQL1064N  DB2STOP processing was successful.\nSQL1064N  DB2STOP processing was successful.\n04/01/2024 07:05:00     0   0   SQL1063N  DB2START processing was successful.\nSQL1063N  DB2START processing was successful.\nWolverine HA management state was enabled successfully.\n\n*********************************************************************************\n********* Installation and configuration of DB2 completed successfully! *********\n*********************************************************************************\n\nRemoving BLUDB from DB2 instance 1\nDB20000I  The FORCE APPLICATION command completed successfully.\nDB21024I  This command is asynchronous and may not be effective immediately.\n\nDB20000I  The DEACTIVATE DATABASE command completed successfully.\nDB20000I  The DROP DATABASE command completed successfully.\n\nExisting databases on DB instance #1 are:\n\nRemoving temporary files...\nDone.\n\n***********************************************\n********* DB2 Connection Information: *********\n***********************************************\n\nUse this hostname/IP to access the databases e.g. with IBM Data Studio.\n   Hostname instance 1: router-default.apps.ocp.ibm.edu\n   Other possible addresses(If hostname not available above): 10.100.1.21,compute1.ocp.ibm.edu\n\nUse one of these NodePorts to access the databases e.g. with IBM Data Studio (usually the first one is for legacy-server (Db2 port 50000), the second for ssl-server (Db2 port 50001)).\nInstance 1: \n                  \"nodePort\": 30505,\n                  \"nodePort\": 30107,\n\nUse \"db2inst1\" and password \"passw0rd\" to access the databases e.g. with IBM Data Studio.\n\nDb2u installation complete! Congratulations. Exiting...\n</code></pre> <ol> <li>While the script is running, you optionally can review the changes applied:</li> </ol> <p>a. First, the IBM DB2 Operator Catalog is deployed, see   db2OperatorCatalog.yaml   in folder   cp4ba-rapid-deployment/cp4ba-23-0-2/mycluster/deployment-db2-cp4ba   . An operator catalog gives you access to a set of operators, for example the D2 operator.</p> <p>b. A new project in OCP is created using a by the 02 script generated file named   db2-namespace.yaml   . This file gets generated from template file   db2-namespace.template.yaml   by injecting some of the parameters from   01-parametersForDb2OnOCP.sh   , for example parameter   db2OnOcpProjectName   that is set to value   ibm-db2   .</p> <p>c. A new secret is created in the new project using your Entitlement Registry key named   ibm-registry   .</p> <pre><code>  Note: A dummy email is used by the scripts.\n</code></pre> <p>d. The OpenShift Global Pull Secret is modified to ensure you can pull the container images for DB2.</p> <p>e. An Operator Group object for DB2 Operator is created. The 02 script generated a file named   db2-operatorgroup.yaml   . This file gets generated from template file   db2-operatorgroup.template.yaml   by injecting some of the parameters from   01-parametersForDb2OnOCP.sh   .</p> <p>f. A Subscription for the DB2 Operator is created. The 02 script generated a file named   db2-subscription.yaml   . This file gets generated from template file   db2-subscription.template.yaml   by injecting some of the parameters from   01-parametersForDb2OnOCP.sh   . For example, the namespace (project name), channel and startingCSV are set.</p> <pre><code>  Applying this Subscription causes the DB2 operator to install. As you can see in the definition, installPlanApproval is set to Manual. This is to avoid DB2 operator to automatically update to latest version as this can cause issues while the DB2 instance deployment. Therefore, the script has to approve the first DB2 Operator install plan to allow the version provided under startingCSV to install. Install plans generated afterwards should not get approved by you manually to avoid issues while the creation of the DB2 instance.\n</code></pre> <p>g. Once the DB2 Operator is installed, the script is deploying the Db2u cluster. For this, the 02 script generated a file named   db2.yaml   . This file gets generated from template file   db2.template.yaml   by injecting some of the parameters from   01-parametersForDb2OnOCP.sh   . For example, the namespace, license, admin user password and instance version are set.</p> <pre><code>  Applying this resource causes the Db2u cluster to be installed using the specified parameters.\n\n  Between the applied files there are multiple dependencies, for example between DB2 Operator version installed (startingCSV) and Db2u cluster version installed. For example, newer DB2 Operators will not install older Db2u cluster versions and vice versa. Due to the rapid deployment scripts and the set of default values provided by them, beginners don\u2019t need to care about such dependencies. Advanced users could modify these properties as well to deploy newer DB2 versions, for example also on a newer OpenShift version. But, in some cases changing the parameters in   01-parametersForDb2OnOCP.sh   is not sufficient, further changes in the .template. files will most likely be needed, too.\n</code></pre> <p>h. Once the Db2u cluster is up and running, the 02 script waits till the job   c-db2ucluster-restore-morph   completes, which is the last step in deploying the cluster. Then, the script does also apply some further configuration changes to the Db2u cluster, performs a full re-start of DB2 and drops the default database BLUDB as this one is not needed for your CP4BA deployment. Last but not least some useful information is provided in case you want to connect to this DB2 cluster with for example IBM Data Studio.</p> <ol> <li>Once the script completed, review the script output and ensure there are no errors, and that it is completed as shown in the sample script output.</li> </ol> <p>If you you have hit an issue and you don't know how to resolve it, please reach out to your hosting staff.</p> <ol> <li>Look at the output of your script and verify that the deletion of BLUDB was successful. If this is not the case, delete it manually.</li> </ol> <p>Note: This database is created out of the box by DB2 but is not needed for the CP4BA deployment.</p> <ol> <li>Run this command and verify that you see two completed pods and five pods Running and Ready (1/1).</li> </ol> <pre><code>oc get pods\n</code></pre> <p>You have now successfully installed the DB2 Operator, and run the Operator to create a DB2 instance.</p> <p>To continue, refer to Exercise 3: Create DB2 Databases.</p>"},{"location":"Bring-up/Bring-Up-Lab-1/Exercise-3-Create-DB2-Databases/","title":"Exercise 3: Create DB2 Databases","text":""},{"location":"Bring-up/Bring-Up-Lab-1/Exercise-3-Create-DB2-Databases/#31-introduction","title":"3.1 Introduction","text":"<p>A CP4BA production mode deployment requires you to provide the databases needed by the CP4BA components. In this exercise, you'll create the needed databases on the containerized DB2 you previously installed on the OpenShift cluster.</p> <p>You will run a script provided by the rapid deployment scripts to create the needed databases. For the selected CP4BA deployment template - ibm_cp4a_cr_template.002.ent.FoundationContent.yaml - three databases will be required: - ICNDB - database for Navigator - GCDDB - database for Content Platform Engine - CLOS - database for one CPE Object Store</p>"},{"location":"Bring-up/Bring-Up-Lab-1/Exercise-3-Create-DB2-Databases/#32-exercise-instructions","title":"3.2 Exercise Instructions","text":"<ol> <li>Run this command to verify you are still connected with OCP.</li> </ol> <pre><code>oc version\n</code></pre> <p>Note: If you are not connected to OCP, follow the instructions in Exercise 1: Prepare yourself for this Bring-Up Lab to reconnect.</p> <ol> <li>Make sure to be in the right directory.</li> </ol> <pre><code>cd /home/cp4badmin/Desktop/Labfiles/cp4ba-rapid-deployment/cp4ba-23-0-2/mycluster/deployment-db2-cp4ba\n</code></pre> <ol> <li>Run script 03-createCp4baDBs4Db2OnOCP.sh to create the databases needed for the CP4BA template that you selected.</li> </ol> <pre><code>./03-createCp4baDBs4Db2OnOCP.sh\n</code></pre> <p>Note: You can ignore the following warning:</p> <pre><code>SQL1363W  One or more of the parameters submitted for immediate modification were not changed dynamically.\nFor these configuration parameters, the database must be shutdown and reactivated before the configuration\nparameter changes become effective.\n</code></pre> <ol> <li>Review the output of the script and make sure there were no errors and that the following three databases were created:</li> </ol> <p></p> <p>Note: In case you got errors creating DBs, please use script 99-dropCp4baDBs4Db2OnOCP.sh to drop all DBs \u2013 then re-run script 03-createCp4baDBs4Db2OnOCP.sh. More databases will be created when selecting a larger CP4BA template for deployment.</p> <ol> <li>Verify that the script also has activated these databases:</li> </ol> <p></p> <p>Note: If you got errors activating DBs, please use script 04-activateDBs.sh to try to activate them again \u2013 if your DB2 pod got enough memory assigned according to the template used, activation of all DBs must be successful.</p> <p>You have now successfully created all needed databases.</p> <p>To continue, refer to Exercise 4: Deploy CP4BA Operator.</p>"},{"location":"Bring-up/Bring-Up-Lab-1/Exercise-4-Deploy-CP4BA-Operator/","title":"Exercise 4: Deploy CP4BA Operator","text":""},{"location":"Bring-up/Bring-Up-Lab-1/Exercise-4-Deploy-CP4BA-Operator/#41-introduction","title":"4.1 Introduction","text":"<p>To install the Cloud Pak 4 Business Automation, two modes are available. The Starter type deployment is useful for demonstrations, and includes the deployment of most prerequisites such as LDAP Server and databases. Tn this Lab guide however the Production deployment type is used instead, which can also be used for demonstrations, but also for deployments, which are used in production environments of customers. The procedure is described in the knowledge center in the \"Installing Production Deployments\" section, available from https://www.ibm.com/docs/en/cloud-paks/cp-biz-automation/23.0.2?topic=installing-production-deployments.</p> <p>In Production deployments, separate installations of the databases and an LDAP server are needed. The LDAP server has been pre-installed in the lab environment used for this exercise, and the installation of the databases has been completed in previous exercises.</p> <p>For the installation, the case package is used, which is available for download in Github. The case package is maintained by the IBM Product Development teams, and for every new ifix an updated script package is available. The links to the case packages can be found on the \"Cloud Pak for Business Automation Interim fix download document\", which is available from https://www.ibm.com/support/pages/node/6576423.</p> <p>For the successful deployment of Cloud Pak for Business Automation, apart from Database and LDAP Server, storage volumes to store the persistent storage requests need to be created. While the required storage volumes can be created manually, if needed, in this Lab a Storage Class will be used, a suitable one has also been provided with the Lab environment, this is checked in one of the steps below.</p> <p>For the main deployment of the CP4BA Operator, the documentation lists different possible solutions in the section \"Setting up the cluster\", available at https://www.ibm.com/docs/en/cloud-paks/cp-biz-automation/23.0.2?topic=deployment-setting-up-cluster. In this lab, the approach to \"Setting up the cluster by running a script\" is used, which performs the required steps for creating the project, setting up the operator user account, deploying the cert manager and license manager, creating the secret for accessing the container library and finally setting up the CP4BA Operators. Those steps can be done separately too, in case a customer requires it. The alternative would be a more graphical deployment through forms done on the OCP Administration GUI.</p> <p>The exercise instructions in the following paragraph will guide you through the download and unpacking of the case package. Scripts available in the case package are then used to deploy the Cloud Pak for Business Automation operators, the Licensing Operator and the Certificate Manager Operator into the Openshift cluster. Correct installation is reviewed in the following section called \"Verification instructions\".</p>"},{"location":"Bring-up/Bring-Up-Lab-1/Exercise-4-Deploy-CP4BA-Operator/#42-exercise-instructions","title":"4.2 Exercise Instructions","text":"<ol> <li> <p>Connect to your bastion host as documented in Exercise 1: Prepare yourself for this Bring-Up Lab. Login as the cp4badmin user, if needed, the password is passw0rd (where the third-last character is a zero).</p> </li> <li> <p>Open a Terminal, by clicking the link on the desktop. Switch to the Labfiles directory to host there the product deployment scripts.</p> </li> </ol> <pre><code>cd /home/cp4badmin/Desktop/Labfiles\n</code></pre> <ol> <li>Buy running the following commands, create a temporary directory, e.g., <code>/tmp</code>, download the CP4BA 23.0.2 IF002 Case package: https://github.com/IBM/cloud-pak/raw/master/repo/case/ibm-cp-automation/5.1.2/ibm-cp-automation-5.1.2.tgz into that temporary directory, and extract <code>ibm-cp-automation-5.1.2.tgz</code> into the same temporary directory.</li> </ol> <pre><code>mkdir tmp\n</code></pre> <pre><code>cd tmp\n</code></pre> <pre><code>wget https://github.com/IBM/cloud-pak/raw/master/repo/case/ibm-cp-automation/5.1.2/ibm-cp-automation-5.1.2.tgz\n</code></pre> <pre><code>tar xvfz ibm-cp-automation-5.1.2.tgz\n</code></pre> <ol> <li>Extract the content of archive ibm-cp-automation/inventory/cp4aOperatorSdk/files/deploy/crs/cert-k8s-23.0.2.tar into the Labfiles directory, delete the temporary directory.</li> </ol> <pre><code>cd ..\n</code></pre> <pre><code>tar xvf tmp/ibm-cp-automation/inventory/cp4aOperatorSdk/files/deploy/crs/cert-k8s-23.0.2.tar\n</code></pre> <pre><code>rm -r tmp\n</code></pre> <ol> <li>Change into the cert-kubernetes/scripts directory</li> </ol> <pre><code>cd cert-kubernetes/scripts\n</code></pre> <ol> <li>Before running the script, make sure that you are connected through the oc CLI.</li> </ol> <pre><code>oc version\n</code></pre> <p>Note: If you are not connected to OCP, follow the instructions in Exercise 1: Prepare yourself for this Bring-Up Lab to reconnect. </p> <ol> <li>Start the deployment of the CP4BA Operator by running the clusteradmin setup script.</li> </ol> <pre><code>./cp4a-clusteradmin-setup.sh\n</code></pre> <ol> <li>The script initially prompts you for some input. First, select the correct type of environment. This environment uses an Openshift-environment on Private Cloud that is not ROKS, so select 2, and hit the Enter key.</li> </ol> <p></p> <ol> <li>Next, select the type of deployment to do. In this lab we will create a Production type deployment, so select 2 again, and hit the Enter key.</li> </ol> <p></p> <ol> <li> <p>For the question whether to check the nodes if they are FIPS compliant, select No, and hit the Enter key.</p> </li> <li> <p>For the question whether to use a private catalog select No as well, and hit the Enter key.</p> <p></p> <p>Note: Private catalogs are recommended if you plan to deploy multiple Cloud Paks or multiple instances of the same Cloud Pak on the same OpenShift cluster. In such cases, private catlogs will allow you to individually upgrade the version of a deployment without any dependencies to the other deployments.</p> </li> <li> <p>For the question, into which Openshift project the CP4BA should be deployed, answer ibm-cp4ba, and hit the Enter key.</p> <p></p> </li> <li> <p>On the next question, a user needs to be selected. Select the user ocpadmin as well, by typing in the number, which is displayed in front of his name.</p> </li> <li> <p>The next question is, if you have an entitlement key. Answer Yes and hit the Enter key.</p> </li> <li> <p>Now the system is querying on the CP4BA Entitlement Registry key, paste your key ONCE. It will not be displayed. Then, hit the Enter key.</p> <p>Notes:</p> <p>You need your Entitlement Registry key handy, see also https://myibm.ibm.com/products-services/containerlibrary.</p> <p>When you paste your Entitlement Registry key, it will not be shown; therefore, paste it just once and hit the Enter key.</p> <p>At this point, no more questions need to be answered, and the script begins installation of the Cloud Pak for Business Automation Operator. It starts by installing the cert manager and the licensing manager, each into its own namespace. Then it installs the CP4BA Catalog Sources into the OCP cluster, then it installs the CP4BA Operator into the ibm-cp4ba project.</p> <p>The script can take between 15 minutes to half an hour to complete.</p> <p>It might happen that the script times out when installing the licensing service. If this happens, re-run the cluster admin script, see step 7 and following above.</p> <p></p> </li> </ol>"},{"location":"Bring-up/Bring-Up-Lab-1/Exercise-4-Deploy-CP4BA-Operator/#43-verification-instructions","title":"4.3 Verification Instructions","text":"<p>When the script finishes successfully, it should have installed the CP4BA Operators.</p> <ol> <li>Change to Firefox, and login to the Openshift Web Console as ocpadmin, using password passw0rd (where the third-last character is a zero). To verify the operators' deployment, select the menu entry Installed Operators on the left-hand side within Operators, and change the project scope to ibm-cp4ba. Verify that the following seven operators show Status Succeeded.</li> </ol> <p></p> <p>Note: In different CP4BA versions, you may see more or fewer operators.</p> <ol> <li>At the top left side of the main pane, switch to project ibm-licensing. Verify that the following two operators show Status Succeeded.</li> </ol> <p></p> <ol> <li>Change project to ibm-cert-manager and verify that the following operator shows Status Succeeded.</li> </ol> <p></p> <ol> <li>Select on the left-hand side within Workloads the menu entry Pods. Verify that you see four CertManager pods, all Running and Ready (1/1).</li> </ol> <p></p> <ol> <li>Switch to project ibm-licensing. Verify that you see two Licensing pods, all Running and Ready (1/1).</li> </ol> <p></p> <ol> <li>Finally, switch to project ibm-cp4ba. Verify that the following eleven pods exist, all Running and Ready 1/1).</li> </ol> <p></p> <p>Note: In different CP4BA versions, You may see more pods.</p> <p>Congratulations, the Cloud Pak for Business Automation operators, as well as the LicenseManager and CertManager operators seem to be installed properly.</p> <p>Last but not least, let's deploy CP4BA in Exercise-5: Deploy CP4BA.</p>"},{"location":"Bring-up/Bring-Up-Lab-1/Exercise-5-Deploy-CP4BA/","title":"Exercise 5: Deploy CP4BA","text":""},{"location":"Bring-up/Bring-Up-Lab-1/Exercise-5-Deploy-CP4BA/#51-introduction","title":"5.1 Introduction","text":"<p>You have now completed all prerequisites for the CP4BA deployment: LDAP is installed on the bastion host, DB2 is deployed on the OpenShift cluster, and the needed databases are created. Also, the CP4BA Operators are deployed.</p> <p>You are now ready to get started with the deployment of the CP4BA Cluster!</p> <p>The first step is to verify LDAP is running correctly.</p> <p>Then you have to provide some more CP4BA-specific configuration parameters and then you can kick off the CP4BA deployment using the CP4BA Operator.</p> <p>Finally, there are some post-deployment and verification steps to verify that the deployment is healthy and that all deployed components are accessible.</p>"},{"location":"Bring-up/Bring-Up-Lab-1/Exercise-5-Deploy-CP4BA/#52-exercise-instructions","title":"5.2 Exercise Instructions","text":""},{"location":"Bring-up/Bring-Up-Lab-1/Exercise-5-Deploy-CP4BA/#521-deploy-cp4ba","title":"5.2.1 Deploy CP4BA","text":"<p>Follow these step-by-step instructions to deploy CP4BA using the rapid deployment scripts:</p> <ol> <li> <p>Connect to your bastion host as documented in Exercise 1: Prepare yourself for this Bring-Up Lab. Login as the cp4badmin user, if needed, the password is passw0rd (where the third-last character is a zero).</p> </li> <li> <p>Open a Terminal, by clicking the link on the desktop. Then, check that the Security Directory Server is running fine.</p> </li> </ol> <pre><code>systemctl status sds\n</code></pre> <p>Expected output:</p> <p></p> <p>If you don't see <code>Active: active (running)</code> use these commands to stop and start SDS:</p> <pre><code>sudo systemctl stop sds\n</code></pre> <pre><code>sudo systemctl start sds\n</code></pre> <ol> <li>Run this command to verify you are still connected with OCP.</li> </ol> <pre><code>oc version\n</code></pre> <p>Note: If you are not connected to OCP, follow the instructions in Exercise 1: Prepare yourself for this Bring-Up Lab to reconnect.</p> <ol> <li>Switch to the directory where you previously downloaded the rapid deployment scripts into.</li> </ol> <pre><code>cd /home/cp4badmin/Desktop/Labfiles/cp4ba-rapid-deployment/cp4ba-23-0-2/mycluster/deployment-db2-cp4ba\n</code></pre> <ol> <li>Open rapid deployment script 05-parametersForCp4ba.sh, with gedit.</li> </ol> <pre><code>gedit 05-parametersForCp4ba.sh\n</code></pre> <ol> <li> <p>Apply the following changes:</p> </li> <li> <p>cp4baProjectName \u2013 Name of the project/namespace to use to deploy CP4BA, for example, ibm-cp4ba \u2013 make sure to use the same value as used before when running script <code>cp4a-clusteradmin-setup.sh</code></p> <p>set the value to ibm-cp4ba</p> </li> <li> <p>cp4baTlsSecretName \u2013 Parameter for ROKS deployments on IBM Cloud only \u2013 as you are not deploying on ROKS, leave empty</p> <p>remove the default value REQUIRED, and leave this parameter empty</p> </li> <li> <p>cp4baAdminPassword \u2013 Use the password for user cp4badmin (this user was for you created in the LDAP server).</p> <p>set the value to passw0rd (where the third-last character is a zero)</p> </li> <li> <p>ldapAdminPassword \u2013 Use the password that was specified for cn=root when setting up LDAP</p> <p>set the value to passw0rd123 (where the sixth character is a zero)</p> </li> <li> <p>ldapServer \u2013 The hostname or IP of the LDAP server</p> <p>set the value to \"10.100.1.8\"</p> </li> <li> <p>The changes you made so far should look as shown below.</p> <p></p> </li> <li> <p>Leave all other properties at their default values</p> <p>The storage class nfs-client available on your OpenShift cluster from TechZone is already referenced under properties named cp4baScXXX and cp4baBlockScFast as default value.</p> </li> <li> <p>Save your changes and close the editor</p> </li> <li> <p>Run script 07-createCp4baDeployment.sh. This script will now deploy CP4BA using the parameters you previously provided in 01-parametersForDb2OnOCP.sh and 05-parametersForCp4ba.sh.</p> </li> </ol> <pre><code>./07-createCp4baDeployment.sh\n</code></pre> <p>Notes:</p> <p>This script will prompt you for various input. Please have a look at the sample script output provided below to see the answers you must use.</p> <p>You need your Entitlement Registry key handy, see also https://myibm.ibm.com/products-services/containerlibrary.</p> <p>When you paste your Entitlement Registry key, it will not be shown; therefore, paste it just once and hit the Enter key.</p> <p>Sample script output:</p> <pre><code>./07-createCp4baDeployment.sh\n\nFound 01-parametersForDb2OnOCP.sh.  Reading in variables from that script.\n   Reading 01-parametersForDb2OnOCP.sh ...\nDone!\n\nFound 05-parametersForCp4ba.sh.  Reading in variables from that script.\n   Reading 05-parametersForCp4ba.sh ...\n   Extracting OCP Hostname\n   OCPHostname set to apps.ocp.ibm.edu\nDone!\n\nUsing correct cp4ba version.\n\nThis script PREPARES and optionaly CREATES the CP4BA deployment using template ibm_cp4a_cr_template.002.ent.FoundationContent.yaml in project ibm-cp4ba. \n\nAre 01-parametersForDb2OnOCP.sh and 05-parametersForCp4ba.sh up to date, and do you want to continue? (Yes/No, default: No): Yes   &lt;--- Enter Yes here\n\nPreparing the CP4BA deployment...\n\nSwitching to project ibm-cp4ba...\nAlready on project \"ibm-cp4ba\" on server \"https://api.ocp.ibm.edu:6443\".\n\nCollecting information for secret ibm-entitlement-key. For this, your Entitlement Registry key is needed.\n\nYou can get the Entitlement Registry key from here: https://myibm.ibm.com/products-services/containerlibrary\n\nEnter your Entitlement Registry key: &lt;paste your Entitlement Registry key here ONCE, it will not be shown, then hit the Enter key&gt;\nVerifying the Entitlement Registry key...\nLogin Succeeded!\nEntitlement Registry key is valid.\n\nDeployment of CP4BA required synchronied clocks among the server nodes.\nSynchronize clocks now (y/n) ? n   &lt;--- Enter n here\nNot synchronizing clocks...\n\nPreparing the CP4BA secrets...\n\nPreparing the CR YAML for deployment...\n\nAll artefacts for deployment are prepared.\n\nDo you want to CREATE the CP4BA deployment in project ibm-cp4ba now? (Yes/No, default: No): Yes   &lt;--- Enter Yes here\n\nCreating the CP4BA deployment...\nCreating secret ibm-entitlement-key in project ibm-cp4ba...\nAlready exists\nAlready on project \"ibm-cp4ba\" on server \"https://api.ocp.ibm.edu:6443\".\n\nCreating CP4BA secrets...\nsecret/ldap-bind-secret created\nsecret/icp4a-shared-encryption-key created\nsecret/resource-registry-admin-secret created\nsecret/ibm-ban-secret created\nsecret/ibm-fncm-secret created\nsecret/icp4adeploy-bas-admin-secret created\nsecret/playback-server-admin-secret created\nsecret/icp4adeploy-workspace-aae-app-engine-admin-secret created\nsecret/ibm-adp-secret created\nsecret/ibm-bawaut-server-db-secret created\nsecret/ibm-pfs-admin-secret created\nsecret/ibm-bawaut-admin-secret created\nsecret/ibm-odm-db-secret created\nsecret/ibm-ier-secret created\nDone.\n\nCreating the CP4BA deployment...\nicp4acluster.icp4a.ibm.com/icp4adeploy created\nDone.\n\nAll changes got applied. Exiting...\n</code></pre>"},{"location":"Bring-up/Bring-Up-Lab-1/Exercise-5-Deploy-CP4BA/#522-cp4ba-deployment-verification","title":"5.2.2 CP4BA Deployment Verification","text":"<p>The deployment of CP4BA might take some time, usually about one hour.</p> <p>You can monitor the progress of the deployment either through the OpenShift Web Console in the  Web Browser or by command line using the <code>oc get pods</code> command or monitor the Operator's logs to spot any potential issues.</p> <p>This particular deployment is complete, when you see pod icp4adeploy-navigator-watcher-xxxxx in Running and Ready (1/1) state.</p> <p>Note: As part of the CP4BA deployment, additional operators are added to project ibm-cp4ba.</p> <ol> <li>In the OCP Web Console, change project to ibm-cp4ba.</li> </ol> <p></p> <ol> <li>Once the deployment has finished, you should see 40 Running and Ready pods, and about 12 or 13 Completed pods, but no Pending / CrashLoopBackOff pods.</li> </ol> <p></p> <p>Note: Some pods may be in Failed or Error state. For those, ensure another instance of that pod is in the Completed state. If this is the case, you can delete the Failed or Error pods. If there are pods in Failed or Error state where there is no other instance of that pod in a Completed state, the deployment is not healthy.</p> <p>In different CP4BA versions, you may see more pods.</p>"},{"location":"Bring-up/Bring-Up-Lab-1/Exercise-5-Deploy-CP4BA/#523-post-deployment-steps-enable-log-in-with-the-users-from-ldap","title":"5.2.3 Post Deployment Steps - Enable log-in with the users from LDAP","text":"<ol> <li>Get the user ID and password of the zen admin user by running those two commands:</li> </ol> <pre><code>oc get secret ibm-iam-bindinfo-platform-auth-idp-credentials -o jsonpath='{.data.admin_username}' | base64 -d &amp;&amp; echo\n</code></pre> <pre><code>oc get secret ibm-iam-bindinfo-platform-auth-idp-credentials -o jsonpath='{.data.admin_password}' | base64 -d &amp;&amp; echo\n</code></pre> <p>Note: By default, the user id is cpadmin.</p> <ol> <li> <p>Switch to your Web Browser tab with the OCP Web Console and select Networking &gt;  Routes.</p> </li> <li> <p>If not on project ibm-cp4ba, switch to it.</p> </li> <li> <p>In the Location column on the cpd Route, click on the URL to open the cpd route in a new tab.</p> </li> </ol> <p></p> <ol> <li>Accept the self-signed certificate.</li> </ol> <p>Note: For deploying the CP4BA Cluster, properly signed certificates can be created, which don't raise security exceptions in the Web Browser. This requires having SSL Certificates from a Certificate Authority, which would be available, for example, in an OCP environment on IBM Cloud.</p> <ol> <li> <p>On the Log in to IBM Cloud Pak screen, select IBM-provided credentials (cpadmin only).</p> </li> <li> <p>Log in using the zen admin user credentials you gathered in Step 1.</p> </li> </ol> <p></p> <ol> <li>You now see the IBM Cloud Pak Welcome page. Click Manage users.</li> </ol> <p></p> <ol> <li>Select tab User groups and click New user group.</li> </ol> <p></p> <ol> <li> <p>Enter the name cp4bausers and click Next.</p> </li> <li> <p>On the Users page, select Identity provider groups, search for cp4bausers, select the result and click Next.</p> <p></p> </li> <li> <p>On the Roles page, select Automation Developer (needed for CP4BA, for example, to access BAStudio) and User, then click Next.</p> <p></p> </li> <li> <p>On the Summary page, review the selections and click Create.</p> </li> <li> <p>Verify that the new group got created. Then, select the Users tab and click cp4badmin.</p> <p></p> </li> <li> <p>Click on Assign roles.</p> </li> <li> <p>Select all roles and click Assign 4 roles.</p> <p></p> </li> <li> <p>Verify the roles where assigned successfully. Then, log out with the zen admin user.</p> </li> </ol>"},{"location":"Bring-up/Bring-Up-Lab-1/Exercise-5-Deploy-CP4BA/#524-post-deployment-steps-verify-that-ldap-users-can-log-in","title":"5.2.4 Post Deployment Steps - Verify that LDAP users can log in","text":"<ol> <li> <p>Click Log in.</p> </li> <li> <p>As Log in with option, select this time Enterprise LDAP.</p> </li> <li> <p>Log in with cp4badmin, a user from LDAP. The password is passw0rd (where the third-last character is a zero).</p> </li> <li> <p>Verify that cp4badmin now has full administrative access to zen - cp4badmin should also see the Manage users option, and in the hamburger menu the entry Administration.</p> <p> </p> </li> </ol>"},{"location":"Bring-up/Bring-Up-Lab-1/Exercise-5-Deploy-CP4BA/#525-post-deployment-steps-verify-that-the-deployed-cp4ba-components-function-correctly","title":"5.2.5 Post Deployment Steps - Verify that the deployed CP4BA components function correctly","text":"<p>In this chapter you will gather the cluster's URLs from config map icp4adeploy-cp4ba-access-info and test that all URLs work.</p> <ol> <li> <p>Switch to the Browser tab with OpenShift Web Console open.</p> </li> <li> <p>Select Workloads &gt; ConfigMaps.</p> </li> <li> <p>Search for icp4adeploy-cp4ba-access-info.</p> <p></p> </li> <li> <p>Click icp4adeploy-cp4ba-access-info to open this config map.</p> </li> <li> <p>Scroll down to the Data &gt; cpe-access-info section.</p> </li> <li> <p>In a new Web Browser tab, open the URL for Content Platform Engine administration</p> </li> </ol> <p>Note: As you are already logged in as cp4badmin, the ACCE will show up.</p> <ol> <li>Expand Object Stores and verify CONTENT is available.</li> </ol> <p></p> <p>Note: As part of the deployment it's possible to initialize the CPE domain and object stores. The selected template for deployment, creates P8DOMAIN and object store CONTENT.</p> <ol> <li> <p>Switch back to OpenShift Web Console tab where config map icp4adeploy-cp4ba-access-info is shown.</p> </li> <li> <p>Locate Business Automation Navigator for CP4BA URL in the navigator-access-info section.</p> </li> <li> <p>In a new Browser tab, open Business Automation Navigator for CP4BA URL.</p> <p></p> <p>Note: The hamburger menu provides you access to some other navigator desktops.</p> </li> <li> <p>Similarly, verify the following two URL pages open correctly.</p> <ul> <li> <p>Content Management Interoperability Services for CP4BA (log in with cp4badmin / passw0rd, where the third-last character is a zero)</p> </li> <li> <p>Content Services GraphQL</p> </li> </ul> </li> </ol>"},{"location":"Bring-up/Bring-Up-Lab-1/Exercise-5-Deploy-CP4BA/#53-summary","title":"5.3 Summary","text":"<p>You have completed this exercise and learned how to leverage the CP4BA rapid deployment scripts to install CP4BA on an OCP cluster.</p>"},{"location":"Bring-up/Bring-Up-Lab-1/Exercise-5-Deploy-CP4BA/#531-about-cp4ba-rapid-deployment-scripts","title":"5.3.1 About CP4BA Rapid Deployment Scripts","text":"<p>The CP4BA rapid deployment scripts (https://github.com/IBM/cp4ba-rapid-deployment) are accessible by customers, business partners, and IBMers. The IBM Automation SWAT team continuously maintains them. Feel free to use them.</p> <p>At the moment, only one template is available for CP4BA version 23.0.2, the one you used while this lab. Moving forward, more templates will get added to the rapid deployment scripts that allow you to rapidly install more CP4BA patterns.</p> <p>Congratulations! You have now successfully installed IBM Cloud Pak for Business Autiomation version 23.0.2 IF002 on your OpenShift cluster using the rapid deployment scripts. With that, this lab is complete.</p> <p>Now that you completed all exercises of this lab, you can do the Quiz for Bring-up Lab 1 to earn the Badge for Lab 1.</p>"},{"location":"Bring-up/Bring-Up-Lab-2/","title":"Bring-up Lab - Lab 2 \u2013 Using Regular Deployment Scripts","text":"<p>Version 1.0</p>"},{"location":"Bring-up/Bring-Up-Lab-2/#authors","title":"Authors","text":"<ul> <li>Thomas Schulze - ThomasSchulze@de.ibm.com</li> <li>Matthias Jung - matthias.jung@de.ibm.com</li> <li>Jorge D. Rodriguez - jorgedr@us.ibm.com</li> <li>Zhong Tao Gao - gaozt@cn.ibm.com</li> </ul>"},{"location":"Bring-up/Bring-Up-Lab-2/#introduction","title":"Introduction","text":""},{"location":"Bring-up/Bring-Up-Lab-2/#ibm-cloud-pak-for-business-automation","title":"IBM Cloud Pak for Business Automation","text":"<p>IBM Cloud Pak for Business Automation (CP4BA) assembles certified software from the IBM Automation Platform for Digital Business on multiple cloud infrastructures. It offers design, build, run, and automation services to rapidly scale your programs and fully execute and operationalize an automation strategy.</p> <p>You can read more about CP4BA here: https://www.ibm.com/docs/en/cloud-paks/cp-biz-automation/23.0.2?topic=overview-what-is-cloud-pak-business-automation</p>"},{"location":"Bring-up/Bring-Up-Lab-2/#lab-overview","title":"Lab Overview","text":"<p>In this Lab, you will learn how to configure and install the CP4BA Production mode on an OpenShift cluster using the regular deployment scripts. </p> <p>The regular deployment scripts cover a wide area of different deployments, support Air-Gap deployment and encryption of all communication channel,  and are thus the preferred choice for deployment of customer environments which can be used on Production environments. They are available on  public GitHub (https://github.com/IBM/cloud-pak/blob/master/repo/case/ibm-cp-automation/index.yaml) and, therefore, can be used by customers,  business partners, and IBMers.</p> <p>The regular deployment scripts are available for all CP4BA versions.</p> <p>As part of this Lab, you will only deploy PostgreSQL and CP4BA. All other required steps were already completed, so you can concentrate  on the essential part: Configure and Install IBM Cloud Pak for Business Automation version 23.0.2 on Red Hat OpenShift.</p> <p>We have created a TechZone environment preconfigured with a bastion host and a three-worker node Red Hat OpenShift cluster. In addition,  IBM Security Directory Server (SDS) was installed and configured on the bastion host required by CP4BA. To fit the size of the OpenShift  cluster, it is recommended to use Content pattern for use by the regular deployment scripts. This pattern will install foundational services  required by CP4BA and Filenet Content Manager components.</p> <p>While inclusion of other patterns is very similar, including other patterns would increase system resources required for building a deployment,  beyond resources available on the TechZone environment. </p> <p>During the first exercise, you will reserve an environment on TechZone, access it, and verify that your RedHat OpenShift cluster is working correctly.</p> <p>The following seven exercises will guide you through configuring and installing CP4BA version 23.0.2.</p> <p>Finally, a chapter with troubleshooting instructions is available for you to work through.</p>"},{"location":"Bring-up/Bring-Up-Lab-2/#notation","title":"Notation","text":"<p>Paragraphs formatted like the below contain excerpts from configuration files, or commands to enter in a Terminal window. The paragraph can be copied to the clipboard by using an icon available on the right edge of the grey area.</p> <pre><code>whoami\n</code></pre> <p>Paragraphs like the below contain additional information, which would help to understand further concepts. While it is not needed to read them, if the only wish is to follow the guide to get a CP4BA environment running, the information in those sections might also be used on badge questions.</p> <p>The above command shows the name of the user, who was used to logon to the operation system. While you typically know who you are, and might not need it, this command is often used in shellscripts.</p> <p>Approximate Duration: 8 hours</p>"},{"location":"Bring-up/Bring-Up-Lab-2/#table-of-exercises","title":"Table of Exercises","text":"<ul> <li>Exercise 1: Prepare yourself for this Bring-Up Lab </li> </ul> <p>Guides you through reserving of the Lab Environment, customization of the Bastion node, and consistency checking of the Openshift environment.</p> <ul> <li>Exercise 2: Deploy the CP4BA Operator</li> </ul> <p>The Case Package is downloaded, and the clusteradmin setup script used to deploy the CP4BA Operators. Required preconditions are verified.</p> <ul> <li>Exercise 3: Preparing the Deployment</li> </ul> <p>A script in the case package is used to specify the deployment to be done. The script generates property files to supply further configuration, as a result.</p> <ul> <li>Exercise 4: Deployment of Database</li> </ul> <p>A database operator is used from the OCP Operator hub, and used to deploy a PostgreSQL database. The configuration values for database server, and portname are extracted, and verified. The database server and user property configuration files are modified with required configuration values.</p> <ul> <li>Exercise 5: Configure LDAP</li> </ul> <p>Connectivity to the pre-configured SDS installation from the Openshift Cluster is verified, along with the LDAP Password, and the user and group names. The information is used to update the LDAP property file of the CP4BA deployment.</p> <ul> <li>Exercise 6: Generate CP4BA Configuration and Databases</li> </ul> <p>The CP4BA Configuration Prerequisites are generated, this creates database creation scripts and Kubernetes Secrets. The </p> <ul> <li>Exercise 7: Deploy CP4BA</li> </ul> <p>The last part is generated, this is the so-called \"Custom Resource\". The file is handed over to Openshift for building the cluster.</p> <ul> <li>Exercise 8: Post Deployment Steps</li> </ul> <p>Find out if deployment has completed, make cp4badmin user a real administrator, and find the URLs of the deployed components</p> <ul> <li>Apppendix A: Troubleshooting CP4BA Deployment</li> </ul> <p>If things dont work as they should, this section might help to identify the cause of the problem.</p>"},{"location":"Bring-up/Bring-Up-Lab-2/#notices","title":"Notices","text":"<p>This information was developed for products and services offered in the USA.</p> <p>IBM may not offer the products, services, or features discussed in this document in other countries. Consult your local IBM representative for information on the products and services currently available in your area. Any reference to an IBM product, program, or service is not intended to state or imply that only that IBM product, program, or service may be used. Any functionally equivalent product, program, or service that does not infringe any IBM intellectual property right may be used instead. However, it is the user's responsibility to evaluate and verify the operation of any non-IBM product, program, or service.</p> <p>IBM may have patents or pending patent applications covering subject matter described in this document. The furnishing of this document does not grant you any license to these patents. You can send license inquiries, in writing, to:</p> <p>IBM Director of Licensing IBM Corporation North Castle Drive, MD-NC119 Armonk, NY 10504-1785 United States of America  </p> <p>The following paragraph does not apply to the United Kingdom or any other country where such provisions are inconsistent with local law: INTERNATIONAL BUSINESS MACHINES CORPORATION PROVIDES THIS PUBLICATION \"AS IS\" WITHOUT WARRANTY OF ANY KIND, EITHER EXPRESS OR IMPLIED, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF NON-INFRINGEMENT, MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE. Some states do not allow disclaimer of express or implied warranties in certain transactions, therefore, this statement may not apply to you.</p> <p>This information could include technical inaccuracies or typographical errors. Changes are periodically made to the information herein; these changes will be incorporated in new editions of the publication. IBM may make improvements and/or changes in the product(s) and/or the program(s) described in this publication at any time without notice. </p> <p>Any references in this information to non-IBM websites are provided for convenience only and do not in any manner serve as an endorsement of those websites. The materials at those websites are not part of the materials for this IBM product and use of those websites is at your own risk.</p> <p>IBM may use or distribute any of the information you supply in any way it believes appropriate without incurring any obligation to you.</p> <p>Information concerning non-IBM products was obtained from the suppliers of those products, their published announcements or other publicly available sources. IBM has not tested those products and cannot confirm the accuracy of performance, compatibility or any other claims related to non-IBM products. Questions on the capabilities of non-IBM products should be addressed to the suppliers of those products.</p> <p>This information contains examples of data and reports used in daily business operations. To illustrate them as completely as possible, the examples include the names of individuals, companies, brands, and products. All of these names are fictitious and any similarity to the names and addresses used by an actual business enterprise is entirely coincidental.</p>"},{"location":"Bring-up/Bring-Up-Lab-2/#trademarks","title":"Trademarks","text":"<ul> <li> <p>IBM, the IBM logo, and ibm.com are trademarks or registered trademarks of International Business Machines Corp., registered in many jurisdictions worldwide. Other product and service names might be trademarks of IBM or other companies. A current list of IBM trademarks is available on the web at \u201cCopyright and trademark information\u201d at www.ibm.com/legal/copytrade.shtml.</p> </li> <li> <p>Adobe, the Adobe logo, PostScript, and the PostScript logo are either registered trademarks or trademarks of Adobe Systems Incorporated in the United States, and/or other countries. </p> </li> <li> <p>Cell Broadband Engine is a trademark of Sony Computer Entertainment, Inc. in the United States, other countries, or both and is used under license therefrom. </p> </li> <li> <p>Intel, Intel logo, Intel Inside, Intel Inside logo, Intel Centrino, Intel Centrino logo, Celeron, Intel Xeon, Intel SpeedStep, Itanium, and Pentium are trademarks or registered trademarks of Intel Corporation or its subsidiaries in the United States and other countries. </p> </li> <li> <p>IT Infrastructure Library is a Registered Trade Mark of AXELOS Limited. </p> </li> <li> <p>ITIL is a Registered Trade Mark of AXELOS Limited. </p> </li> <li> <p>Java and all Java-based trademarks and logos are trademarks or registered trademarks of Oracle and/or its affiliates. </p> </li> <li> <p>Linear Tape-Open, LTO, the LTO Logo, Ultrium, and the Ultrium logo are trademarks of HP, IBM Corp. and Quantum in the U.S. and other countries. </p> </li> <li> <p>Linux is a registered trademark of Linus Torvalds in the United States, other countries, or both. </p> </li> <li> <p>Microsoft, Windows, Windows NT, and the Windows logo are trademarks of Microsoft Corporation in the United States, other countries, or both. </p> </li> <li> <p>UNIX is a registered trademark of The Open Group in the United States and other countries.</p> </li> </ul> <p>\u00a9 Copyright International Business Machines Corporation 2024. </p> <p>This document may not be reproduced in whole or in part without the prior written permission of IBM. US Government Users Restricted Rights - Use, duplication or disclosure restricted by GSA ADP Schedule Contract with IBM Corp.</p>"},{"location":"Bring-up/Bring-Up-Lab-2/Appendinx-A-Troubleshooting/","title":"Appendix A: Troubleshooting CP4BA","text":""},{"location":"Bring-up/Bring-Up-Lab-2/Appendinx-A-Troubleshooting/#a1-introduction","title":"A.1 Introduction","text":"<p>When you finish the previous exercise, you are ready with the deployment of Cloud Pak For Business Automation. However, you might have run into troubles or might be interested in how to  further troubleshooting can be made for the deployment of a Cloud Pak For Business Automation deployment. Also, during the exercises above, you might have been referred to one or more of the sections in this chapter for troubleshooting problems, or checking the availability of components. </p>"},{"location":"Bring-up/Bring-Up-Lab-2/Appendinx-A-Troubleshooting/#a2-determining-deployment-status-of-the-cp4ba-cluster","title":"A.2 Determining Deployment Status of the CP4BA Cluster","text":"<p>This section shows how you can check the correct installation of the various parts of the CP4A deployment steps. Use it as a guide to check where you are with the deployment and whether anything failed to install.</p> <p>First, performing any action while the Openshift cluster is being upgraded should be avoided. Therefore, before running any other task, determine if the Openshift cluster is currently being upgraded, and perform the following steps:</p> <ol> <li> <p>Open the Browser and use the bookmark to log in to the Openshift Web Console. Login using ocpadmin / passw0rd, the thir-last character of the password is a zero.</p> </li> <li> <p>On the left navigation bar open the section Compute and select Machine Config Pools.</p> </li> <li> <p>Verify on the right side if you see true on the column Updating.</p> <p></p> </li> </ol> <p>One of the first activities for CP4BA deployment is running the cp4a-clusteradmin-setup.sh script. When the script terminates, the CP4BA Operators might not be fully installed. Please check:</p> <ol> <li> <p>Open the Web Browser and use the bookmark to log in to the Openshift Web Console. Login using ocpadmin / passw0rd.</p> </li> <li> <p>On the left navigation bar, open the Operators section and select Installed Operators. Then select the project ibm-cp4ba.</p> </li> <li> <p>Check that all of the operators show Status Succeeded.</p> </li> </ol> <p>After the clusteradmin script was executed, for preparation of the prerequisites, the CloudNativePG Postscript operator is installed. To determine if the PostgreSQL Operator is currently being installed or the Postgres cluster is being configured do the following:  </p> <ol> <li> <p>Open the Browser and use the bookmark to log in to the Openshift Web Console. Login using ocpadmin / passw0rd.</p> </li> <li> <p>On the left navigation bar, open the Operators section and select Installed Operators.</p> </li> <li> <p>Then select the project ibm-cp4ba. The CloudNativePG Operator should be there and show Status Succeeded. If that's not the case, it might still be installed.</p> <p></p> </li> <li> <p>Then open the CloudNativePG Operator, and scroll to the bottom of the Details tab. At the bottom of it you should see the following if the Operator is already fully installed:</p> <p></p> </li> <li> <p>When the CloudNativePG Operator is completely installed, the next step would be to install a PostgreSQL database server. To check the PostgreSQL Status using the CloudNativePG Operator, go to the All instances tab and verify the Status of the postgres cluster. When the Postgres Cluster is deployed, the state should show as Cluster in healthy state, as here:</p> <p></p> </li> </ol> <p>When the prerequisites are setup, and the <code>cp4a-prerequisites.sh</code> was successfully executed in validate mode, the CP4BA cluster CR will be applied to the OCP environment. The CP4BA deployment uses either the resource type ICP4ACluster, or the resource type Content, depending on the components which were selected during the deployment. </p> <ol> <li> <p>Switch to the Firefox window, and login to the Openshift Web Console. Open the Home menu, and select Search. Make sure you use the ibm-cp4ba project. Click on Resources and type in Content, if \"only\" FileNet components were deployed, or type in ICP4ACluster if also other components were included. Press return to display all custom resources for the \"Content\" or \"ICP4ACluster\" Custom Resource Definition, in project ibm-cp4ba.</p> <p> </p> </li> <li> <p>Click on the object which comes, the name will probably be \"content\" or \"icp4adeploy\". On the lower part of the screen, the conditions of this deployment are listed. The deployment is complete when the row with Type \"Ready\" reaches status \"true\", as outlined below.</p> <p> </p> </li> <li> <p>For further troubleshooting, use the script deploymentStatus.sh. By right-clicking the Raw  button the script can be saved to a local directory and executed. On a healthy environment it should print following output for a Content deployment:</p> </li> </ol> <pre><code>--------------------------------------------------------------\n\nContent CR named content found\nCustom Resource of type Content is applied\n    Running      True    Running Running reconciliation\n    Ready        True    Successful\n\nZenService Deployment Progress: 100% (The Current Operation Is Completed)\nZenStatus: zen operator 5.1.1 build 37:  Completed\n\nFoundation:\n        Running reconciliation\n        Prerequisites execution done.\n\nInitialization Status:\n{\n        cpe_initialized: True,\n        cpe_os_number: 2,\n        css_initialized: True,\n        nav_initialized: True\n}\n\nIAM Login details: cpadmin / &lt;password&gt;\n</code></pre>"},{"location":"Bring-up/Bring-Up-Lab-2/Exercise-1-Prepare/","title":"Exercise 1: Prepare yourself for this Bring-Up Lab","text":""},{"location":"Bring-up/Bring-Up-Lab-2/Exercise-1-Prepare/#11-introduction","title":"1.1 Introduction","text":"<p>This exercise verifies that you have all prerequisites in place and instructs you how to reserve your lab environment. The lab environment  consists of a Bastion Host VM and a Red Hat OpenShift Container Platform (OCP) Cluster with three master and three worker VMs.</p>"},{"location":"Bring-up/Bring-Up-Lab-2/Exercise-1-Prepare/#111-bastion-host-vm","title":"1.1.1 Bastion Host VM","text":"<p>A bastion host is a computer from which you access the OpenShift cluster through the command line to administrate the OCP cluster.  Administration of an OCP cluster also includes the configuration and installation of new software such as CP4BA. To do that, this Lab  shows you how to use the scripts and information provided by the CP4BA development teams, by executing these scripts on the bastion host.  Therefore, the bastion host must be one of RHEL, CentOS, or macOS. Finally, all commands these scripts need  must also be available on the bastion host, for example, the OpenShift CLI, Kubernetes CLI, and so on.</p> <p>The preparation of a bastion host is discussed in the documentation on this page: Preparing a client to connect to the cluster.</p> <p>Other services are also deployed on this specific bastion host. The most important ones are the LDAP Server, which is used as the Authentication provider for the CP4BA deployment, and an NFS Server to provide persistent storage capabilities to the Openshift cluster.</p>"},{"location":"Bring-up/Bring-Up-Lab-2/Exercise-1-Prepare/#112-red-hat-openshift-container-platform-ocp-cluster-vms","title":"1.1.2 Red Hat OpenShift Container Platform (OCP) Cluster VMs","text":"<p>The OpenShift cluster was configured using OCP version 4.12.45. It will host the PostgreSQL and CP4BA containers which you will install  later in this Lab. You can access your OCP cluster from the bastion host either by command line (oc command) or the OpenShift Web Console by Browser.</p>"},{"location":"Bring-up/Bring-Up-Lab-2/Exercise-1-Prepare/#12-exercise-instructions","title":"1.2 Exercise Instructions","text":"<p>Before you can start this Lab, you need the following prerequisites: - an entitlement key, and - an environment with a bastion host and OpenShift cluster from TechZone.</p> <p>Note: All the tools such as podman and OpenShift command-line interface needed while the lab are already available on the provided bastion host.</p>"},{"location":"Bring-up/Bring-Up-Lab-2/Exercise-1-Prepare/#121-get-the-entitlement-key","title":"1.2.1 Get the Entitlement Key","text":"<p>To complete this Lab, you must have an entitlement key with access to pull CP4BA images from the IBM Container Software Library <code>cp.icr.io</code>.</p> <ol> <li> <p>Check that you have an entitlement key with the proper image access. For this, please open https://myibm.ibm.com/products-services/containerlibrary    and log in with your IBM ID. IBMers can use their w3 ID.</p> </li> <li> <p>Then, switch to the Container software library page. IBMers and some Business Partners will see the following, which means that they do have     such an entitlement key available:</p> </li> </ol> <p></p> <p>Business Partners that do not see all here, before proceeding, must verify that CP4BA is listed on the Container software library page.  If you don\u2019t see a CP4BA license listed, you can request here a CP4BA 60-day Trial license: https://www.ibm.com/account/reg/us-en/signup?formid=urx-44505.  You cannot perform this bring-up Lab without a license and entitlement key.</p>"},{"location":"Bring-up/Bring-Up-Lab-2/Exercise-1-Prepare/#122-reserve-the-openshift-tech-zone-envrioment","title":"1.2.2 Reserve the OpenShift Tech Zone Envrioment","text":"<ol> <li> <p>To get an OpenShift cluster from TechZone, access IBM Technology Zone: https://techzone.ibm.com/</p> </li> <li> <p>To sign-in, either use your IBM ID or your company credentials if SSO is set up between your company and IBM. For example, if you have an     IBM W3 or IBM Partnerworld ID, you should use this ID.</p> <p>Note: Dependent on the IBM ID used to sign in, you may or may not be able to reserve a demo. If you can't reserve a demo with the current IBM ID,  check if you have another IBM ID that is enabled for IBM Technology Zone reservations. </p> </li> <li> <p>Once signed in, open the lab resource page: https://techzone.ibm.com/collection/ibm-cloud-pak-for-business-automation-demos-and-labs-bring-up-lab/</p> </li> <li> <p>Scroll down to the Environments section. Choose an environment with the highest version number. If you have multiple with the highest number, choose the one in the nearest geo. Then click on Reserve.</p> <p></p> <p>Note: If you don't see the tile, go back to step 1 and sign in with a different ID.</p> </li> <li> <p>Select Reserve now. </p> <p></p> </li> <li> <p>On the next page, provide the necessary information: Provide the Purpose, e.g., \"Practice / Self-Education\", a description, select the geography      closest to your location and select the end time and date for the reservation. Plan for at least 8 hours, maybe more. Then click Submit.</p> <p> </p> </li> <li> <p>After you click Submit, you'll get some emails from IBM Technology Zone. Provisioning the environment will take about 75 minutes, then you should      get the second email informing you that your environment is Ready. </p> <p></p> </li> </ol> <p>In case there was an issue provisioning the environment, delete the reservation and try again later.</p> <p>Once you get the email informing you that your environment is Ready, you can start your Lab.</p>"},{"location":"Bring-up/Bring-Up-Lab-2/Exercise-1-Prepare/#123-access-the-openshift-tech-zone-envrioment","title":"1.2.3 Access the OpenShift Tech Zone Envrioment","text":"<ol> <li> <p>On your local machine, click on View My Reservations. In the browser window, select the reservation for the Bring Up lab. </p> </li> <li> <p>At the top of the reservation, you see a link to a Remote Desktop Service (RDP). Copy the link provided to the clipboard, and try running your      favorite Remote Desktop client with the RDP link. If that is working, its the preferred way to connect to the Bastion host of the Openshift environment.     Should that not be possible, please skip to step xx.</p> <p></p> </li> <li> <p>If the Remote Desktop connection can be used, the RDP login screen is shown. Login to the Bastion machine using the user account cp4badmin      and password passw0rd (where the third-last character is a zero). Skip to step 6.</p> <p></p> <p>Note: Login is only possible either through RDP, or through the VM Remote Console (see below). You cannot use both methods at the same time, with the same user account.</p> </li> <li> <p>Should it not be possible to connect through RDP, then scroll down on the reservation, until you find the section with the title \"VM Remote Console\".      In the upper left corner you can find a blue tile. The first two lines contain the name of the machine. For the bastion host, it ends in \"bastion\".     Click on it to open the remote console of the bastion host. </p> <p></p> <p>A window opens with the console window.</p> </li> <li> <p>Log-in to the desktop of the bastion host, by clicking on the cp4badmin user and using password  using passw0rd (where the third-last character is a zero).</p> <p></p> <p>Note: If you see the current time and date after login, press the Space key. If the screen is blank, move the mouse. </p> </li> <li> <p>Once you logged in, you see the Red Hat Enterprise Linux (RHEL) Server desktop of your bastion host. Ensure the VM is connected to the network      before proceeding. Check that the network icon in the top right corner shows connected. The environment is not usable if the VM is not correctly connected to the network. </p> <p>Connected:  (if not connected that icon will not be shown)</p> </li> <li> <p>Open the Firefox by double clicking on the Firefox icon on the desktop. Use the link in the browser toolbar to navigate to the Tech Jam Labs. Open the lab instructions     from inside the bastion host. This will allow you to copy&amp;paste from the lab instructions much easier.</p> </li> <li> <p>If you are logged on using the \"VM Remote Console\" window, click Full Screen button in upper right corner. Notice that you can still switch to other windows using the      Alt-Tab keyboard combination from Windows clients.</p> <p></p> </li> <li> <p>Change the size and resolution of the desktop to your liking. Open Applications \u2192 System Tools \u2192 Settings. Scroll down and click Devices. Change the Display settings to your liking. </p> <p></p> </li> <li> <p>Finally, to change the keyboard to your liking, this depends on weather you use RDP or VM Remote Console. On VM Remote Console, we recommend to leave the keyboard configured to en.      If possible, install on your local machine the US keyboard layout, switch to it, and use the US keyboard layout, while working with the Bastion host. When using RDP, it should be possible to adapt the keyboard layout of the Bastion host to the one you use on your your local machine instead.</p> <p>In any case, you can change the keyboard layout of the bastion host on the pull down menu in upper right corner. From there, you can also bring up a window showing you the current keyboard layout.</p> <p></p> <p>To check that your keyboard works as expected, open Firefox and enter some special language characters in the URL field. </p> </li> <li> <p>To access your OpenShift cluster through a Browser, open Firefox first (shortcut on the desktop).In Firefox, open bookmark OpenShift Web Console</p> <p>Note: In case you get the Warning: Potential Security Risk Ahead, click Advanced\u2026 and then click Accept the Risk and Continue. This is needed two times to finally get to the OCP log-in screen.</p> </li> <li> <p>Log in with ocpadmin / passw0rd (where the third-last character is a zero).</p> </li> <li> <p>Once logged in, verify that the OpenShift Web Console opens and that you have Administrator access.</p> <p></p> </li> <li> <p>When you check the status of the cluster, the Cluster and the Control Plane are green, but one Operator is degrated. By clicking on the link for Operators you can see that the machine-config operator is degraded. The reason is, that Updates of the Machine Config were disabled, before creating the copy of the OCP cluster.</p> <p></p> </li> <li> <p>In the navigation area, browse to Compute, and select Machine Config Pools. Note that Updates have been paused.</p> <p></p> </li> <li> <p>On both lines, master and worker, click on the three vertical dots menu, and select Resume Updates. The status will change to Up To Date or Updating. If it changes to Updating, await further status change to Up To Date. </p> <p></p> </li> <li> <p>Navigate back to Overview in the Home section of the navigation area. Check that the Status of Cluster, Control Plane and Operators is green, that should happen automatically after a while, after updates were resumed.</p> <p></p> </li> <li> <p>On the Overview page, the main page, scroll down and verify that the Cluster inventory shows no errors.</p> <p></p> <p>Note: The number of pods shown here could be different to what you will see. For Pods, you might see one pod in error and / or one to multiple progressing pods:</p> <p></p> <p>The progressing icon should disappear automatically after a while.</p> </li> <li> <p>To get rid of the pods in error click on the red icon behind Pods. You\u2019ll now see a list of pods that are in error, for example:</p> <p></p> <p>If you only see such an ip-reconciler pod in the list, click the three dots at the end and delete that pod. In case of other errors, warnings, or pending indicators,  consult the Troubleshooting section to resolve those. </p> </li> <li> <p>To log in through the oc command line interface, expand ocpadmin in the top right corner and select Copy login command.</p> <p></p> </li> <li> <p>A new tab opens. Log in again with ocpadmin / passw0rd (where the third-last character is a zero) and select Display Token.</p> <p></p> </li> <li> <p>Copy the entire oc login command to the clipboard.</p> <p></p> </li> <li> <p>Open a Terminal window, paste the clipboard's content, and hit Enter.</p> <p></p> </li> <li> <p>Next, run this command</p> </li> </ol> <pre><code>oc version\n</code></pre> <pre><code>Expected output:\n\n![oc version output](Images/2.2.3-oc-version.png)\n</code></pre> <p>You have now successfully accessed and updated your environment and are ready to start the CP4BA deployment. </p> <p>To continue, refer to Exercise 2: Deploy Operator.</p>"},{"location":"Bring-up/Bring-Up-Lab-2/Exercise-2-Deploy-Operator/","title":"Exercise 2: Deploy the CP4BA Operator","text":""},{"location":"Bring-up/Bring-Up-Lab-2/Exercise-2-Deploy-Operator/#21-introduction","title":"2.1 Introduction","text":"<p>To install the Cloud Pak 4 Business Automation, two modes are available. The Starter type deployment is useful for demonstrations, and includes the deployment of most prerequisites such as LDAP Server and databases. Tn this Lab guide however the Production deployment type is used instead, which can also be used for demonstrations, but also for deployments, which are used in production environments of customers. The procedure is described in the knowledge center in the \"Installing Production Deployments\" section, available from https://www.ibm.com/docs/en/cloud-paks/cp-biz-automation/23.0.2?topic=installing-production-deployments. </p> <p>In Production deployments, separate installations of the databases and an LDAP server are needed. The LDAP server has been pre-installed in the lab environment used for this exercise, and the installation of the databases will be done in a later exercise. Furthermore, Production type deployments also support Air-Gap installations, where Starter type deployments don't support Air-Gapped installations.</p> <p>For the installation, the case package is used, which is available for download in Github. The case package is maintained by the IBM Product Development teams, and for every new ifix an updated script package is available. The links to the case packages can be found on the \"Cloud Pak for Business Automation Interim fix download document\", which is available from https://www.ibm.com/support/pages/node/6576423. </p> <p>For the successful deployment of Cloud Pak for Business Automation, apart from Database and LDAP Server, storage volumes to store the persistent storage requests need to be created. While the required storage volumes can be created manually, if needed, in this Lab a Storage Class will be used, a suitable one has also been provided with the Lab environment, this is checked in one of the steps below.</p> <p>For the main deployment of the CP4BA Operator, the documentation lists different possible solutions in the section \"Setting up the cluster\", available at https://www.ibm.com/docs/en/cloud-paks/cp-biz-automation/23.0.2?topic=deployment-setting-up-cluster. In this lab, the approach to \"Setting up the cluster by running a script\" is used, which performs the required steps for creating the project, setting up the operator user account, deploying the cert manager and license manager, creating the secret for accessing the container library and finally setting up the CP4BA Operators. Those steps can be done separately too, in case a customer requires it. The alternative would be a more graphical deployment through forms done on the OCP Administration GUI.</p> <p>Note about Air-Gap deployments: This refers to the installation of Cloud Pak 4 Business Automation in environments, which have no access to \"the internet\", and thus cannot use the IBM Container Library and other Container registries directly for deployment. The CP4BA Version 23.0.2 now supports version 3.0 of the Air-Gap, through deployment of an addon to the Openshift commandline program \"oc\".</p> <p>In Air-Gap deployments, usually a local registry is used, and images from the IBM Container library are copied into that local registry. Furthermore, Openshift is configured by using an Image Content Source Policy, to search the local registry whenever specific images (specified through their SHA256) are referenced from the IBM Container library.</p> <p>When copying of the images to the local registry and setup of the Image Content Source Policy hav completed successfully, deployment of an Air-Gapped environment can be done exactly like a regular, non air-gapped one.</p> <p>The exercise instructions in the following paragraph will guide you through the download and unpacking of the case package. Scripts available in the case package are then used to deploy the Cloud Pak 4 Business Automation operators, the Licensing Operator and the Certificate Manager Operator into the Openshift cluster. Correct installation is reviewed in the following section called \"Verification instructions\".</p>"},{"location":"Bring-up/Bring-Up-Lab-2/Exercise-2-Deploy-Operator/#22-exercise-instructions","title":"2.2 Exercise Instructions","text":"<ol> <li> <p>Click on the tile for the Bastion host. Login as the \"cp4badmin\" user, if needed, the password is \"passw0rd\" with a zero.</p> </li> <li> <p>Open a Terminal, by clicking the link on the desktop. Create a directory to host the product deployment scripts. </p> </li> </ol> <pre><code>mkdir cp4ba\n</code></pre> <ol> <li> <p>Open Firefox through clicking on the link on the desktop. Find the link for CP4BA Case Packages in the Bookmark toolbar, and navigate to it. The Case Package Directory for the Cloud Pak For Business Automation can be found here: https://github.com/IBM/cloud-pak/tree/master/repo/case/ibm-cp-automation. The document index.yaml contains a mapping of directory names to CP4BA Version numbers.  Click it to determine the directory for the Version 23.0.2. (There might be a typo on the version number.)</p> </li> <li> <p>Click the back arrow, and navigate to the folder named \"5.1.0\". In the folder click the \"ibm-cp-automation-5.1.0.tgz\" file.</p> </li> <li> <p>Click the download arrow on the file to store it in the Downloads folder.</p> <p></p> </li> <li> <p>Back on the terminal window, navigate to the cp4ba directory, and unpack the case package.</p> </li> </ol> <pre><code>cd cp4ba\ntar xvfz ../Downloads/ibm-cp-automation-5.1.0.tgz\n</code></pre> <ol> <li>The case package contains a tar file containing the actual deployment scripts. Unpack that file in current directory. First search it:</li> </ol> <pre><code>find . -name \\*.tar\n</code></pre> <ol> <li>Copy &amp; Paste the returned filename into the tar command:</li> </ol> <pre><code>tar xvf (filename)\n</code></pre> <pre><code>Expected output:\n![tar xvf](Images/3.1-tarxf.png)\n</code></pre> <ol> <li>Change into the cert-kubernetes/scripts directory</li> </ol> <pre><code>cd cert-kubernetes/scripts\n</code></pre> <ol> <li> <p>Before the operator can be deployed, a connection to the OCP cluster must be established. If you did the previous exercise immediately before this one, the connection should still be valid, nothing needs to be done. If not, use Firefox to login to the OCP Console application, then generate a login command, and paste it into the Terminal window, as shown in the last exercise.</p> </li> <li> <p>Verify, that on openshift a storage class has been created.</p> </li> </ol> <pre><code>oc get storageclasses\n</code></pre> <pre><code>Expected output:\n![Storageclasses](Images/3.1-storageclasses.png)\n</code></pre> <ol> <li>Verify, that the ocpadmin user has indeed clusteradmin privileges. </li> </ol> <pre><code>oc auth can-i create project\n</code></pre> <pre><code>Expected output:\n![Can Create Project](Images/3.1-Can-Create-Project.png)\n</code></pre> <ol> <li>Start the deployment of the CP4BA Operator by running the clusteradmin setup script.</li> </ol> <pre><code>./cp4a-clusteradmin-setup.sh\n</code></pre> <ol> <li> <p>Select the correct type of environment, when the script asks for it. This environment uses an Openshift-environment on Private Cloud that is not ROKS, so select 2</p> <p></p> </li> <li> <p>Select the type of deployment to do. In this lab we will create a Production type deployment, so select 2 again.</p> <p></p> </li> <li> <p>For the question whether to check the nodes if they are FIPS compliant, select no.</p> </li> <li> <p>For the question whether to use a private catalog to support air-gap deployments select no as well.</p> </li> <li> <p>For the question, into which Openshift project the CP4BA should be deployed, answer ibm-cp4ba.</p> <p></p> </li> <li> <p>On the next question, a user needs to be selected  . Select the user ocpadmin as well, by typing in the number, which is displayed in front of his name. </p> </li> <li> <p>When the system is querying on the CP4BA Entitlement Registry key, copy the displayed link into the clipboard. Then select the Firefox browser and open the link in a new tab. On the page of the Knowledge Center, click on the link to My IBM Container Software Library. </p> <p>Note: To avoid entering your credentials to the IBM Container Library in the bastion host, you can also do this on your local machine, and copy over the entitlement key to the bastion host using the Clipboard.</p> </li> <li> <p>After logging in to your IBM account, please verify that you have access to \"Cloud Pak 4 Business Automation\" software, by clicking the \"Container software library\" entry on the left side. Then select the \"Entitlement keys\" entry on the left side, and copy one of the still valid entitlement keys to the clipboard.</p> </li> <li> <p>Back on the Terminal window answer Yes to the question whether you have an entitlement registry key. Then paste the key from the clipboard, when prompted.</p> <p></p> </li> </ol> <p>At this point, no more questions need to be answered, and the script begins installation of the Cloud Pak 4 Business Automation Operator. It starts by installing the cert manager and the licensing manager, each into its own namespace. Then it installs the CP4BA Catalog Sources into the OCP cluster, followed by installing the CP4BA Operator into the ibm-cp4ba project. </p> <p>The script can take between 15 minutes to half an hour to complete.</p> <p>Note: If deployment of the cert manager and/or licensing manager take longer than expected, it might be that the <code>cp4a-clusteradmin-setup script.sh</code> script is aborted with an error message. In this situation it can help to await the existance of running instances of the cert manager and/or license manager , and then re-run the <code>cp4a-clusteradmin-setup script.sh</code>. The script will detect existing deployments of the cert manager and/or license manager and skip deployment of already deployed components.</p>"},{"location":"Bring-up/Bring-Up-Lab-2/Exercise-2-Deploy-Operator/#23-verification-instructions","title":"2.3 Verification Instructions","text":"<p>When the script finishes, it should have installed the CP4BA Operators. </p> <p>Note: The version numbers will show up differently as indicated in the screenshots, as the screenshots were made with a newer IFIX release.</p> <ol> <li> <p>Change to Firefox, and login to the Openshift Web Console as ocpadmin, using password passw0rd, with a zero. To verify the operators' deployment, select the menu entry Installed Operators on the left-hand side within Operators.</p> <p></p> </li> <li> <p>At the top left side of the main pane, switch to project ibm-licensing.</p> <p></p> </li> <li> <p>Verify that the following two operators show Status Succeeded.</p> <p></p> </li> <li> <p>Change project to ibm-cert-manager.</p> <p></p> </li> <li> <p>Verify that the following operator shows Status Succeeded.</p> <p></p> </li> <li> <p>Change project to ibm-cp4ba.</p> <p></p> </li> <li> <p>Verify that the following seven operators show Status Succeeded.</p> <p></p> <p>Note: In different CP4BA versions, you may see more or fewer operators.</p> </li> <li> <p>Select on the left-hand side within Workloads the menu entry Pods.</p> <p></p> </li> <li> <p>Verify that the following 11 pods exist, all Running and Ready 1/1).</p> <p></p> <p>Note: In different CP4BA versions, You may see more pods.</p> </li> </ol> <p>Congratulations, the Cloud Pak 4 business automation operators, as well as the LicenseManager and CertManager operators seem to be installed properly. So lets continue with preparation steps for the CP4BA deployment. Refer to Exercise 3: Prepare Deployment for details.</p>"},{"location":"Bring-up/Bring-Up-Lab-2/Exercise-3-Prepare-Deployment/","title":"Exercise 3: Preparing the Deployment","text":""},{"location":"Bring-up/Bring-Up-Lab-2/Exercise-3-Prepare-Deployment/#31-introduction","title":"3.1 Introduction","text":"<p>Also in older versions of Coud Pak For Business Automation, the case package contained a script, with which a deployment of Cloud Pak for Business Automation can be generated. This script is called <code>cp4a-deployment.sh</code>, and is still used to generate the so-called \"CR\" file, which is a YAML file for the ICP4ACluster custom resource definition and specifies, which components to install for a Cloud Pak For Business Automation Deployment.</p> <p>In more recent versions, support for generating prerequisites, and verification of settings was added to the case package, via a script called <code>cp4a-prerequisites.sh</code>. That script covers creation of required databases, Kubernetes secrets, and can also verify the configuration for known problems. </p> <p>In order to create the correct databases, when running the <code>cp4a-prerequisites.sh</code> already, information about the deployment is required, i.e. what components need to be installed. That information can later be re-used when running the <code>cp4a-deployment.sh</code> script. The <code>cp4a-prerequisites.sh</code> script is used in different stages, those stages are provided to the script by mode values. The first mode, which will also be used here, is the property mode, in which the script will ask about details on the CP4BA deployment to be done, and generate property files. These property then need to be filled out and through this, specificy names of databases, ldap groups, et cetera.</p> <p>Filling out the property values will be done in the next two exercises, step by step. When the property values are all filled out, the <code>cp4a-prerequisites.sh</code> can be invoked in generate mode. In this mode the provided information is taken to create the database creation scripts, as well as the Kuberetes secret definitions. With the generated files, the CP4BA databases need to be created. When this has been completed, with the last mode called validate, the integrity of the prerequisite configuration can be checked, so that the deployment can be completed.</p>"},{"location":"Bring-up/Bring-Up-Lab-2/Exercise-3-Prepare-Deployment/#32-exercise-instructions","title":"3.2 Exercise Instructions","text":"<ol> <li>Switch to the Terminal window. Change to the cert-kubernetes/scripts directory.</li> </ol> <pre><code>cd $HOME/cp4ba/cert-kubernetes/scripts\n</code></pre> <ol> <li>Run the cp4a-prerequisites.sh script in prepare mode. In this mode, information about the deployment is gathered, and property files are generated to supply required parameters.</li> </ol> <pre><code>./cp4a-prerequisites.sh -m property\n</code></pre> <pre><code>&gt; When running it without parameters, it supplies a usage.\n\n&gt; ![Prerequisite Script Usage](Images/4.1-prerequisites-script-usage.png)\n</code></pre> <ol> <li> <p>First step is to collect, which components should be deployed. Select there only the FileNet Content Manager, by selecting 1. Then simply press Return to continue.</p> <p></p> <p>Note that the selection of the components does not need to be repeated, when running the <code>cp4a-deployment.sh</code> script later, as the selected settings are stored and the information is reused.</p> </li> <li> <p>The IBM Content Navigator / Business Automation Navigator and GraphQL will automatically be deployed too. Select the \"Content Search Services\" and \"Content Manager Interoperability Services\" as well, by selecting 1 followed by 2, then press Return to continue.</p> <p></p> </li> <li> <p>As the next step, the script asks for the kind of LDAP server, which will be used. Select the \"IBM Tivoli Directory Server / Security Directory Server\".</p> </li> <li> <p>As the next step, the script asks for the name of the storage class for slow, medium and fast storage volumes, and for block storage volumes. In the last exercise it was shown how to obtain the value. The cluster has only one storage class named nfs-client. Provide that value on all four questions.</p> <p></p> <p>Note: the names of the storage classes are not checked at this point. Checking is done towards the end when invoking the <code>cp4a-prerequisites.sh</code> in validate mode. This allows to create the storage classes as part of the prerequisite installation.</p> </li> <li> <p>Next question is on the deployment size. Select to perform a \"small\" deployment.</p> </li> <li> <p>Next question is to select the kind of database to be used for the deployment. In the next exercise, a Postgres database will be created, so select \"PostgreSQL\".</p> </li> <li> <p>The deployment scripts supports usage of multiple different database servers on a deployment. To differentiate between them, alias names need to be provided. This deployment will use only 1, so select db1 as the alias name(s).</p> <p></p> </li> <li> <p>Supply the name of the Openshift Project / Namespace to deploy into, the value is ibm-cp4ba</p> </li> <li> <p>On the question whether to restrict outbound communication to unknown destinations, select \"No\". </p> <p></p> </li> <li> <p>On the question how many object stores to deploy, select 2.</p> </li> </ol> <p>This concludes the information gathering, and a result page is printed in the Terminal window. </p>"},{"location":"Bring-up/Bring-Up-Lab-2/Exercise-3-Prepare-Deployment/#33-verification","title":"3.3 Verification","text":"<p>The script should have created a directory with property files, for further configuration. </p> <p>List the files in the generated directory:</p> <pre><code>ls -ltR cp4ba-prerequisites\n</code></pre> <p></p> <p>These configuration files need to be filled with values. Before we get to it, we will first deploy the database in the next exercise.</p>"},{"location":"Bring-up/Bring-Up-Lab-2/Exercise-4-Deploy-PostgreSQL/","title":"Exercise 4: Deploy PostgreSQL","text":""},{"location":"Bring-up/Bring-Up-Lab-2/Exercise-4-Deploy-PostgreSQL/#41-introduction","title":"4.1 Introduction","text":"<p>In this section, the PostgreSQL database will be deployed, and the database related property files of the CP4BA deployment updated with required configuration values.  For the deployment of the PostgreSQL database, the Cloud Native PG Postgres operator will be used. The Cloud Native PG Postgres Operator is an open source initiative,  its homepage can be found on https://cloudnative-pg.io/. The operator supports Openshift as well as plain Kubernetes, so called CNCF deployments. For commercial usage,  with needed software support, there exist commercial products derived from the offering from Cloud Native PG.</p>"},{"location":"Bring-up/Bring-Up-Lab-2/Exercise-4-Deploy-PostgreSQL/#42-exercise-instructions","title":"4.2 Exercise Instructions","text":"<ol> <li>Switch to the Terminal window. Change to the cert-kubernetes/scripts directory.</li> </ol> <pre><code>cd $HOME/cp4ba/cert-kubernetes/scripts\n</code></pre> <ol> <li>Review the database property files, to determine further information about required databases.</li> </ol> <pre><code>gedit cp4ba-prerequisites/propertyfile/cp4ba_db_name_user.property\n</code></pre> <ol> <li> <p>The file lists 4 databases, one for the GCD of the FileNet installation, two more for the two object stores, and one for Content Navigator. Close the gedit window again.</p> </li> <li> <p>Switch to Firefox and select or open a tab with the Openshift Web Console. Login as ocpadmin with password passw0rd, if required. Note that the third-last character in the password is a zero. Then select in the menu OperatorHub from the Operator menu</p> <p></p> </li> <li> <p>On the right side, enter postgres in the search prompt, and click on the CloudNativePG tile. The CloudNativePG operator can also be used with plain Kubernetes deployments, it does not depend on Openshift.</p> <p></p> </li> <li> <p>If you want, read through the text which comes. Information from that page will not be included in any badge questions.  When ready, click on Install</p> <p></p> </li> <li> <p>Select to install the operator in a specific project / namespace, and select the ibm-cp4ba namespace for it. Then click on Install.</p> <p></p> </li> <li> <p>Click on Installed Operators to review the deployment of the Operator. When it is ready, the operator should have Status Succeeded. </p> <p></p> <p>Note: The version number can differ from the one in the screenshot, as the CloudNativePG operator is upgraded regularly.</p> </li> <li> <p>Select the Workflow -&gt; Pods menu. The operator pod is named cnpg-controller-manager. Check that the operator pod for the CloudNativePG is running.</p> <p></p> </li> <li> <p>Open a new tab in Firefox and navigate to the LabData/postgres.yaml file. Download the file postgres.yaml to the lab environment. To do that, with the content of the postgres.yaml file displayed in the Github window, right-click on the \"Raw\" link above and save the link to file.</p> <p></p> </li> <li> <p>Change to the Terminal window. Change to the Downloads folder, then check and apply the postgres.yaml file</p> </li> </ol> <pre><code>cd\ncd Downloads\ngedit postgres.yaml\noc apply -f postgres.yaml\n</code></pre> <pre><code>No changes are needed in the **postgres.yaml** file. Review, that the file mentions 4 tablespaces, and also creates two secret for the database user, and the database administrator. The database user will have the name **cp4badbuser**, and the database administrator will have the name **postgres**. Both have the same password, which is passw0rd, with the third-last character being a zero. Then close the editor again.\n</code></pre> <ol> <li>Deployment of PostgreSQL will first create an initialization pod, which sets up the persistent volume claim, then one new Postgres pod will be created. Monitor the output of the <code>oc get pods</code> command until the postgres-1 pod is running</li> </ol> <pre><code>oc get pods\n</code></pre> <ol> <li> <p>The postgres.yaml file contains definitions which will deploy 4 tablespaces, one for each of the needed databases, into separate persistent volumes, which should give better performance over using only a single filesystem for all 4 databases. It assigns the tablespaces to the newly created database user cp4badbuser. The credentials for that user are provided to the secret cp4badbuser-secret, which is defined towards the bottom of the file. Lets verify if that succeeded properly. </p> <p></p> <p>The required command is:</p> </li> </ol> <pre><code>oc exec postgres-1 -- psql -U postgres -c '\\db+'\n</code></pre> <ol> <li>Some of the postgres parameters need further customization, so copy out the parameters file for modification. The first command shows the full pathname of the postgresql.conf configuration file, which is needed for the subsequent commands.</li> </ol> <pre><code>oc exec postgres-1 -- find /var/lib -name postgresql.conf\noc cp postgres-1:/var/lib/postgresql/data/pgdata/postgresql.conf postgresql.conf\n</code></pre> <ol> <li>Now edit the postgresql.conf configuration file.</li> </ol> <pre><code>gedit postgresql.conf\n</code></pre> <ol> <li> <p>The first place to change is the line showing max_connections. Change the value to at least 500, which gives more than 50 connections per JDBC connector, as long as only one CPE pod is used.</p> <p></p> </li> <li> <p>The second place to change is the line showing max_prepared_transactions. Remove the # character in front of the the line, and change the value to support 1000 prepared transactions. Read more about both updates in the CP4BA Documentation: https://www.ibm.com/docs/en/cloud-paks/cp-biz-automation/23.0.2?topic=tpdcpe-using-postgresql-max-connections-max-prepared-transactions</p> <p></p> </li> <li> <p>Save the file and close the editor.</p> </li> <li> <p>Copy back the configuration file into the container. The directory containing it is backed up by a persistent volume, so any changes on it will persist. After copying the container, its required to restart Postgres, so delete the Pod for it to happen.</p> </li> </ol> <pre><code>oc cp postgresql.conf postgres-1:/var/lib/postgresql/data/pgdata/postgresql.conf\noc delete pod postgres-1\n</code></pre> <ol> <li> <p>Next we need to confirm on the server name and port for connections to the database. As PostgreSQL is running in a pod, it can be reached through the service defined for it by the Postgres operator. There are three services, one of them allows modifications as well, it is named postgres-rw. It can be seen that the default port for PostgreSQL is 5432. </p> <p></p> <p>The commands to determine this information are:</p> </li> </ol> <pre><code>oc get service\n</code></pre> <ol> <li> <p>That service is made available through the DNS of Kubernetes, with the name ..svc. Lets check it by opening a shell in the operator pod, and test connectivity.  <p> </p> <p>Of course the curl command cannot terminate, as PostgreSQL is not telnet, so abort it by pressing Ctrl-C. But the verbose output allows checking, if the connection can be made. Within Containers, connectivity cannot be checked with the usual ping command. The required commands are:</p> <pre><code>oc get pod\noc exec &lt;name of ibm-cp4a-operator pod&gt; -it -- bash\ncurl -v telnet://postgres-rw.ibm-cp4ba.svc:5432\n</code></pre> <pre><code>You can close the shell in the Operator pod again.\n</code></pre> <ol> <li>The last step is to update the property files, which have been generated previously, with the information from the Postgres database deployment. Navigate back to the directory containing them, and edit the files.</li> </ol> <pre><code>cd $HOME/cp4ba/cert-kubernetes/scripts/cp4ba-prerequisites/propertyfile\ngedit cp4ba_db_server.property\n</code></pre> <ol> <li> <p>It is suggested to make the window wide enough to not be disturbed by the comments. Modify the server name, port, ssl, and client ssl settings in this file as indicated below.</p> <p></p> <p>Hint: The name of the server had been used in one of the previous steps. You can copy it from there.</p> </li> <li> <p>Save the file, and close the editor. Then invoke the editor again on the other database related property file. Before invoking the editor, just determine how the database password passw0rd looks like, when its base64 encoded, that string is required when editing the next file.</p> </li> </ol> <pre><code>echo -n passw0rd | base64\ngedit cp4ba_db_name_user.property\n</code></pre> <pre><code>**Note:** The **-n** option to echo will suppress the linefeed character, which echo normally prints following the output. If it is included, the linefeed will be part of the base64 encoded string, and might lead to illegal passwords, which are very hard to find later.\n</code></pre> <ol> <li> <p>First step for editing the document is to replace all passwords. You can invoke the search and replace function through the hamburger menu on top right corner (next to the Save button). You can copy and paste both values from the editor, and from the Terminal window. The password needs to be replaced 4 times, for the four databases.</p> <p></p> </li> <li> <p>The next step is to replace the database user name. We will use one user account for all databases, so replace  with cp4badbuser as indicated in the screenshot, 4 times.  <p></p> <li> <p>Review the file, and check, if any further field need to be updated in the file, that should not be the case. So save the file, and quit the editor. </p> </li>"},{"location":"Bring-up/Bring-Up-Lab-2/Exercise-4-Deploy-PostgreSQL/#43-validation-steps","title":"4.3 Validation steps","text":"<p>Successful installation of the DB Server was verified by the steps above already. Successful modification of the database server and users property files will be done through running of the <code>cp4ba-prerequisite.sh</code> script in Validate mode, in a later exercise. </p> <p>A common error not detected (yet) by the prerequisite scripts in validate mode is to forget tuning the database configuration with increasing max connections and allowing prepared transactions. Therefore its recommended to double-check it at this point. Run the following command:</p> <pre><code>oc exec postgres-1 -it -- psql -U postgres -c \"select name,setting from pg_settings where name IN ('max_connections', 'max_prepared_transactions') ;\"\n</code></pre> <p>It should print following table:</p> <p></p> <p>In the Next Exercise the remaining configuration values,  as well as the LDAP-server related configuration values will be updated in the property files.</p>"},{"location":"Bring-up/Bring-Up-Lab-2/Exercise-5-Configure-LDAP/","title":"Exercise 5: Apply LDAP Configuration","text":""},{"location":"Bring-up/Bring-Up-Lab-2/Exercise-5-Configure-LDAP/#51-introduction","title":"5.1 Introduction","text":"<p>In prior exercises, empty property files were created by running the <code>cp4a-prerequisites.sh</code> in generate mode. Some of the property files were also modified with concrete values, in the last exercise, after having created the PostgreSQL database server. </p> <p>In this exercise, the remaining configuration settings will be made. The exercise will also validate that the LDAP Server is running, and can be connected from the CP4BA Operators, by running it to export an LDIF file, with defined users and groups. </p>"},{"location":"Bring-up/Bring-Up-Lab-2/Exercise-5-Configure-LDAP/#52-exercise-instructions","title":"5.2 Exercise Instructions","text":"<ol> <li>Switch to the Terminal window. Change to the propertyfile directory inside the cert-kubernetes/scripts directory.</li> </ol> <pre><code>cd $HOME/cp4ba/cert-kubernetes/scripts/cp4ba-prerequisites/propertyfile\n</code></pre> <ol> <li>Check if the Security Directory Server is running. </li> </ol> <pre><code>systemctl status sds\n</code></pre> <pre><code>Expected output:\n\n![SDS running](Images/6.2-sds-running.png)\n</code></pre> <ol> <li>Determine the IP address of the bastion host. That value will later be the LDAP Server hostname.</li> </ol> <pre><code>ip a\n</code></pre> <pre><code>Expected output, the IP address is marked in red:\n\n![Determine IP Address of Bastion](Images/6.2-ip-addr.png)\n</code></pre> <ol> <li>To check connectivity from the OCP cluster, we will again use the curl command from the ibm-cp4a-operator. Determine first the complete name of the pod, and insert that value in the next command to open a shell. Then verify connectivity with the curl command. You need to abort it again, when seeing that the connection could be established.</li> </ol> <pre><code>oc get pod\noc exec &lt;name of ibm-cp4a-operator pod&gt; -it -- bash\ncurl -v telnet://10.100.1.8:389\n</code></pre> <pre><code>Expected output:\n\n![Check Connectivity to LDAP Server](Images/6.2-ldap-connectivity.png)\n</code></pre> <ol> <li>Still in the shell in the ibm-cp4a-operator, we can verify the ldap credentials as well as getting the usernames</li> </ol> <pre><code>ldapsearch -x -b 'dc=example,dc=com' -H ldap://10.100.1.8:389 -D cn=root -W\n</code></pre> <pre><code>**Note:** Care must be taken when using this command on a production installation, where the connected LDAP Server might be used by all users of a company: The output would be very long, the runtime high. \nIn this kind of environments, query a useful subset of the LDAP Server only.\n\nThe command will prompt for the admin password for the LDAP server. Provide the value **passw0rd123** with a zero. The output should list the DN values of all users and groups, among them the admin user named **cp4badmin** and the group **cp4badmins**. Exit the shell, by pressing Ctrl-D.\n</code></pre> <ol> <li>Before editing the LDAP Server property file, please determine the base64 encoded value for the LDAP server password, it will be needed. (Yes, also this 0 is a zero)</li> </ol> <pre><code>echo -n passw0rd123 | base64\n</code></pre> <pre><code>**Note:** The **-n** option to echo will suppress the linefeed character, which echo normally prints following the output. If it is included, the linefeed will be part of the base64 encoded string, and might lead to illegal passwords, which are very hard to find later.\n</code></pre> <ol> <li>Now edit the LDAP Server property file.</li> </ol> <pre><code>gedit cp4ba_LDAP.property\n</code></pre> <ol> <li> <p>Most of the needed configuration values are contained already in the ldapsearch query executed above. The single exception to this is the SSL support, which would be disabled for now. For completeness, below table contains the values which need to be replaced. Make sure to retain the quotation marks. </p> Config Option Value LDAP_SERVER 10.100.1.8 LDAP_PORT 389 LDAP_BASE_DN dc=example,dc=com LDAP_BIND_DN cn=root LDAP_BIND_DN_PASSWORD {Base64}cGFzc3cwcmQxMjM= LDAP_SSL_ENABLED False LDAP_GROUP_BASE_DN dc=example,dc=com <p>With the rest of the configuration values, it can be changed which LDAP property is used to identify a user or group, and how to determine a groups members. They need only to be changed to perform advanced configuration changes.</p> </li> <li> <p>Before editing the last configuration file, we again need the base64 encrypted value for the cp4badmin user, which we will also use as LTPA password and keystore password. The 0 is a zero.</p> </li> </ol> <pre><code>echo -n passw0rd | base64\n</code></pre> <pre><code>**Note:** The **-n** option to echo will suppress the linefeed character, which echo normally prints following the output. If it is included, the linefeed will be part of the base64 encoded string, and might lead to illegal passwords, which are very hard to find later.\n</code></pre> <ol> <li>Now edit the CP4BA user name configuration file.</li> </ol> <pre><code>gedit cp4ba_user_profile.property\n</code></pre> <ol> <li> <p>When editing the file, all passwords are set to the base64 encrypted value resulting from above command. All admin user names are set to cp4badmin, and all admin groups to cp4badmins. The Object Store users group is set to cp4bausers. There are only few other values to replace. Some values are already preconfigured from the answers provided when generating the property files.</p> Complete Configuration Reference CP4BA.CP4BA_LICENSE=\"non-production\" CP4BA.FNCM_LICENSE=\"non-production\" CP4BA.SLOW_FILE_STORAGE_CLASSNAME=\"nfs-client\" CP4BA.MEDIUM_FILE_STORAGE_CLASSNAME=\"nfs-client\" CP4BA.FAST_FILE_STORAGE_CLASSNAME=\"nfs-client\" CP4BA.BLOCK_STORAGE_CLASS_NAME=\"nfs-client\" CP4BA.ENABLE_FIPS=\"false\" CP4BA.ENABLE_RESTRICTED_INTERNET_ACCESS=\"false\" CONTENT.APPLOGIN_USER=\"cp4badmin\" CONTENT.APPLOGIN_PASSWORD=\"{Base64}cGFzc3cwcmQ=\" CONTENT.LTPA_PASSWORD=\"{Base64}cGFzc3cwcmQ=\" CONTENT.KEYSTORE_PASSWORD=\"{Base64}cGFzc3cwcmQ=\" CONTENT.ARCHIVE_USER_ID=\"cp4badmin\" CONTENT.ARCHIVE_USER_PASSWORD=\"{Base64}cGFzc3cwcmQ=\" CONTENT_INITIALIZATION.ENABLE=\"Yes\" CONTENT_INITIALIZATION.LDAP_ADMIN_USER_NAME=\"cp4badmin\" CONTENT_INITIALIZATION.LDAP_ADMINS_GROUPS_NAME=\"cp4badmins\" CONTENT_INITIALIZATION.CPE_OBJ_STORE_ADMIN_USER_GROUPS=\"cp4bausers\" BAN.APPLOGIN_USER=\"cp4badmin\" BAN.APPLOGIN_PASSWORD=\"{Base64}cGFzc3cwcmQ=\" BAN.LTPA_PASSWORD=\"{Base64}cGFzc3cwcmQ=\" BAN.KEYSTORE_PASSWORD=\"{Base64}cGFzc3cwcmQ=\" BAN.JMAIL_USER_NAME=\"\" BAN.JMAIL_USER_PASSWORD=\"\" <li> <p>Save the configuration file and close the editor.</p> </li>"},{"location":"Bring-up/Bring-Up-Lab-2/Exercise-5-Configure-LDAP/#53-validation-instructions","title":"5.3 Validation Instructions","text":"<p>The settings are validated by running the prerequisites script in generate and validate mode, in later exercises. So, for now please continue to generate and use the Database creation scripts in the Next Exercise.</p>"},{"location":"Bring-up/Bring-Up-Lab-2/Exercise-6-Generating-DBs/","title":"Exercise 6: Generating CP4BA Databases and Verifying Configuration","text":""},{"location":"Bring-up/Bring-Up-Lab-2/Exercise-6-Generating-DBs/#61-introduction","title":"6.1 Introduction","text":"<p>In the last two exercises, the configuration parameters in the property files created by the <code>cp4a-prerequisites.sh</code> script, have been set to the required values. This is a required precondition for  running the <code>cp4a-prerequisites.sh</code> now in generate mode. In this mode, the script will first review completeness of the configuration variables, and will then generate the required Kubernetes secret definitions, as well as sql scripts to create the databases on the PostgreSQL database server.</p> <p>The PostgreSQL database creation scripts need to be copied into the PostgreSQL database server. They need some manual modifications, as PostgreSQL deployments with different operators are different from each other. The DB scripts can be transferred, edited and executed one by one, or as its done here, concatenated to each other and executed as one large script. As the files are in different directories, the concatenation approach seems easier, and is applied here.</p> <p>Attention must be applied with editing of the database creation scripts. If thats done incorrectly, all databases might at the end use a single tablespace, which will limit overall performance. Follow the Valiation steps in the last section to verify which tablespace is defined for which database.</p> <p>Applying the Kubernetes secrets is easy, it can be done using the steps indicated here. Alternatively another script from the case package can also be used.</p> <p>In the verification section of this Exercise, the <code>cp4a-prerequisites.sh</code> script run in validate mode, to validate the configuration and deployment of the prerequisites. As the connection to the database is also verified, and as the database can only be reached from inside the Kubernetes cluster, the checks cannot be run directly on the bastion node, without giving error messages from the unavailable database server. Therefore, to run the validation, the case package script is copied into the <code>/tmp</code> directory of the CP4BA Operator, and run from there. </p>"},{"location":"Bring-up/Bring-Up-Lab-2/Exercise-6-Generating-DBs/#62-exercise-instructions","title":"6.2 Exercise Instructions","text":"<ol> <li>Switch to the Terminal window. Change to the cert-kubernetes/scripts directory.</li> </ol> <pre><code>cd $HOME/cp4ba/cert-kubernetes/scripts\n</code></pre> <ol> <li>Run the cp4a-prerequisites.sh script in generate mode. In this mode, information configured in the property files is reviewed, and the CP4BA Configuration files are generated. </li> </ol> <pre><code>./cp4a-prerequisites.sh -m generate\n</code></pre> <pre><code>If error messages are printed, get back to the last exercise and edit the two property files, to find any configuration value which still contains a `&lt;required&gt;` value.\n\n&gt; Note When running it without parameters, the `cp4a-prerequisites.sh` scriptsupplies a usage.\n\n&gt; ![Usage of prerequisites script](Images/7.1-prerequisites-usage.png)\n</code></pre> <ol> <li> <p>The script does not ask for further input, in this mode. Result of checking the property files is indicated in green or red color, red color indicates errors or missing values. </p> <p>Expected output:</p> <p></p> </li> <li> <p>The database creation scripts are generated in directory cp4ba-prerequisites/dbscript, so change into that directory.</p> </li> </ol> <pre><code>cd cp4ba-prerequisites/dbscript\n</code></pre> <ol> <li>Generate a combined database creation script, by collecting all files ending in .sql, and concatenating into one named dbscript.</li> </ol> <pre><code>find . -name \\*.sql | xargs cat &gt; dbscript\n</code></pre> <ol> <li>Edit the generated script, and comment the create role and the create tablespace commands, as the user and the tablespace have been pre-created through the CloudNativePG Operator. Each statement, create role and the create tablespace should appear 4 times, once for every database. </li> </ol> <pre><code>gedit dbscript\n</code></pre> <ol> <li> <p>Also, some connection reset statements need to be added, because the single DB creation scripts were concatenated. After each statement grant create on tablespace, the statement \"\\c\" needs to be added, to reset the connection to the lastly created database. This is also needed 4 times.</p> </li> <li> <p>Further, in the create database commands, the tablespace clause is missing, when using CP4BA 23.0.2 Base release. The problem is fixed in later IFIXes. They need to be inserted.</p> <p>Refer to Complete Modified DB Creation Script for verification of the completed modifications.</p> </li> <li> <p>For creating the databases, the db creation script needs to be made available in the Postgres Pod. The CloudNativePG Postgres operator automatically protects the container filesystem from modifications. The directory where the database configuration is stored, is an exception. Copy the db creation script into that directory, in the Postgres Pod.</p> </li> </ol> <pre><code>oc cp dbscript postgres-1:/var/lib/postgresql/data/dbscript\n</code></pre> <ol> <li>Now run that script.</li> </ol> <pre><code>oc exec postgres-1 -it -- psql -U postgres -f /var/lib/postgresql/data/dbscript\n</code></pre> <pre><code>Expected output:\n\n![Creating the Databases](Images/7.1-creating-databases.png)\n</code></pre> <ol> <li>Check the created databases with the psql command \\l+</li> </ol> <pre><code>oc exec postgres-1 -it -- psql -U postgres -c '\\l+'\n</code></pre> <pre><code>Expected output:\n\n![Database Listing](Images/7.1-database-listing.png)\n\nVerify especially that the correct tablespaces (last column) are assigned to the databases.\n\nIf the script was not yet correct, and the tablespaces are showing up incorrectly, you can delete the Postgres cluster `oc delete -f postgres.yaml`, recreate it `oc apply -f postgres.yaml`.\nBefore applying the dbscript again, copy the modified postgresql.conf file into the Postgres pod, and rerun Postgres by deleting the pod.\n</code></pre> <ol> <li>The next steps is to apply the generated secrets. Thankfully the secrets are ready and don\u2019t need manual updating.</li> </ol> <pre><code>cd ../secret_template\nfind . -name \\*.yaml | xargs -l oc apply -f\n</code></pre> <pre><code>Expected output:\n\n![Creating K8s Secrets](Images/7.1-creating-secrets.png)\n</code></pre>"},{"location":"Bring-up/Bring-Up-Lab-2/Exercise-6-Generating-DBs/#63-validation-steps","title":"6.3 Validation steps","text":"<p>In this section, the <code>cp4a-prerequisite.sh</code> is executed in validate mode. This is an optional step, but highly recommended to verify consistency of the specification, and check for common problems.</p> <ol> <li>When the databases are created, the settings should be validated before providing the specifications to the CP4BA Operator. As the connection to the Postgres database can only be validated from within a pod, the complete specification script directory needs to be copied into the cp4ba operator.</li> </ol> <pre><code>cd $HOME/cp4ba\noc get pods\noc cp cert-kubernetes &lt;cp4ba operator podname&gt;:/tmp/\n</code></pre> <pre><code>Expected output:\n\n![Copying case package script directory into Operator Pod](Images/7.1-copying-case-package-script-into-operator.png)\n</code></pre> <ol> <li>Run a shell inside the Operator, and run the validation script. At the beginning of its execution, some error messages on unavailable command tput and clear are printed. Those are not harmful.</li> </ol> <pre><code>oc exec &lt;cp4ba operator podname&gt; -it -- bash\ncd /tmp/cert-kubernetes/scripts\n./cp4a-prerequisites.sh -m validate\n</code></pre> <p>Review the generated output. It checks not only the storage class, ldap settings and database settings, but measures also the typical connection delay to the LDAP server and the database. </p> <ol> <li> <p>Expected output of storage class checking:</p> <p></p> <p>With errors in this step, check if the right storage class names were provided, and whether the storage class is defined, by running <code>oc get storageclass</code>. With any updates, it needed to update the configuration, by re-running the prerequisite script in generate mode, see beginning of this chapter for reference.</p> </li> <li> <p>Expected output of secret checking</p> <p></p> <p>With errors in this step, please check if the files with the Kubernetes secrets were correctly applied, see last step of preceding section for reference.</p> </li> <li> <p>Expected output of LDAP connection speed testing</p> <p></p> <p>With errors in this step, check if the SDS is running, and whether the correct IP address and port number were configured in the properties files. If SDS is not running, or not responding correctly, it can be restarted by running <code>sudo systemctl restart sds</code>. If configuration files need to be updated, generate the configuration again, apply the secrets, and rerun these verification steps. If only the latency is bad, this can be ignored in this sample environment. In a production environment of a customer, this would need to be investigated properly.</p> </li> <li> <p>Expected output of Database configuration and connection speed checking</p> <p></p> <p>With errors in this step, determine if the databases are incorrectly created (run the psql command \\l+), or if database server address or database user / password are incorrect. If its needed to recreate the databases, it might be needed to delete the Postgres deployment <code>oc delete -f Postgres.yaml</code>. Check if all resources from PostgreSQL databases are gone, only the operator should still exist. Then follow steps above to recreate the databases. </p> </li> <li> <p>Exit out of the Operator</p> </li> </ol> <pre><code>exit\n</code></pre> <p>Congratulations, with completion of this exercise, the required prerequisites for the deployment of Cloud Pak For Business Automation should be in place. In the next exercise, the case package script <code>cp4a-deployment.sh</code> is used to generate the so-called CR (shorthand for Custom Resource). Applying that YAML file to Kubernetes will kick-start the deployment of the Cloud Pak For Business Automation.</p>"},{"location":"Bring-up/Bring-Up-Lab-2/Exercise-7-Deploy-CP4BA/","title":"Exercise 7: Deploy CP4BA","text":""},{"location":"Bring-up/Bring-Up-Lab-2/Exercise-7-Deploy-CP4BA/#71-introduction","title":"7.1 Introduction","text":"<p>All of the prerequisites required for the deployment of Cloud Pak For Business Automation have been installed in the previous execises, and the configuration has been validated by running the <code>cp4a-prerequisites.sh</code> in validate mode. </p> <p>With successful execution of the validation, the Case Package script <code>cp4a-deployment.sh</code> is invoked. As outlined earlier, the script detects and reuses the information made for the <code>cp4a-prerequisites.sh</code> script, so no real further informtion needs to be provided. The Case package script <code>cp4a-deployment.sh</code> generates the Custom Resource definition, which in our case is a Custom Resource of type Content. Applying it completes the deployment phase, and participants are due for a break to await further deployment done by the Cloud Pak For Business Automation Operators.</p> <p>Note: When deploying only the Content-Pattern, the Case package deployment scripts now generate a Custom Resource of type Content, where a general deployment of Cloud Pak for Business Automation would use the type ICP4ACluster. Gladly, the specifications are needing same settings, with the same syntax, and there would be few, if any settings allowed in one of them, but not on the other. So, if a configuration of type Content needs to be extended by components not covered by the Content Operator, such as Business Automation Insights or Business Automation Workflow, it would be needed to change the type of the CR file accordingly, and applying it to Kubernetes, for the operator to update the environment. Take care to not change the name of the CR file, only the type. </p>"},{"location":"Bring-up/Bring-Up-Lab-2/Exercise-7-Deploy-CP4BA/#72-exercise-instructions","title":"7.2 Exercise Instructions","text":"<ol> <li>Switch to the Terminal window. Change to the cert-kubernetes/scripts directory.</li> </ol> <pre><code>cd $HOME/cp4ba/cert-kubernetes/scripts\n</code></pre> <ol> <li>Run the deployment script.</li> </ol> <pre><code>./cp4a-deployment.sh\n</code></pre> <ol> <li> <p>Indicate that you accept the license.</p> </li> <li> <p>Next question is, if in the current OCP cluster you already have a deployment of FileNet Content Manager using the deployment scripts of FileNet. The answer is \"No\".</p> <p></p> </li> <li> <p>Next question is about the kind of deployment  to do. Answer is Production deployment, so select 2.</p> </li> <li> <p>The script then checks to detect any previously made selection from the prerequisites script. Press Return to continue:</p> <p></p> </li> <li> <p>The deployment goes into an OCP environment on private cloud, so select 2.</p> </li> <li> <p>The next output indicates, that the CP4BA deployment will use an internal administration account named \"cpadmin\". Luckily this is different from the one in our LDAP, which is cp4badmin, and also not any of the users in the LDAP. So answer \"Yes\" to the question whether to use this name.</p> </li> <li> <p>In the next question, the script offers to use customized JDBC drivers. If that would be needed, the drivers need to be made available on a URL. In case of an Air-Gapped environment, this would mean that a webserver needs to be configured as a separate pod. As we can use the provided drivers, we can bypass the question by pressing Return.</p> <p>Note: In case ICCSAP is needed in the configuration, SAP libraries for connecting to SAP need to be provided through this mechanism as well.</p> <p>Note: The provided drivers are also available in the subdirectory \"jdbc\" of the scripts directory after deployment of the cp4ba operator.</p> </li> <li> <p>Next, the script provides a summary of the configuration settings for review. Answer \"Yes\" to indicate the information is correct.</p> </li> <li> <p>The script generates the specification file for Cloud Pak 4 Business Automation in the directory generated-cr. Navigate into this directory, and review the generated file.</p> </li> </ol> <pre><code>cd generated-cr\nls -l \nless ibm_content_cr_final.yaml\n</code></pre> <ol> <li> <p>Note that the deployment scripts have chosen a specification for the \"Content\" Custom Resource Definition, which is being worked by the Content Operator. So any error messages will be logged by the Content Operator. Other deployments of the Cloud Pak for Business Automation, which include other components, such as Business Automation Workflow would require a different kind of specification, using the \"ICP4ACluster\" Custom Resource Definition, which would be worked by the CP4A Operator.</p> <p>Also, the \"CR\", the \"Custom Resource\" as it is called, is not always named \"icp4acluster\". This one has the default name \"content\", which you are free to change if needed. That name though will be used in many derived names, including some of the secret names, so better don\u2019t change it for the moment.</p> </li> <li> <p>For editing Custom Resources, or more general YAML files, it is good to use an editor supporting the special requirements of YAML files, and also supporting syntax highlighting. The author of this lab uses emacs for this purpose, and the yaml-mode for Emacs, which is available through open-source. Of course there are further options.</p> <p>Close less by pressing \u2018q\u2019.</p> </li> <li> <p>Apply the specification.</p> </li> </ol> <pre><code>oc apply -f ibm_content_cr_final.yaml\n</code></pre>"},{"location":"Bring-up/Bring-Up-Lab-2/Exercise-7-Deploy-CP4BA/#73-verification-instructions","title":"7.3 Verification Instructions","text":"<p>At this point, the operator will start deployment according to the specification. During first half hour or so, nothing much will be notable from the working, as foundational components need to be deployed first. </p> <p>If you like looking at some changing text, you can open two Terminal windows and run these two commands in them, one in each. The first one displays the pods which are defined in the current project, the second one fetches the podname of the Content Operator, and displays its logging output,  thereby filtering out the lines containing the word \"info\".</p> <pre><code>watch oc get pods\noc logs $(oc get pod -l name=ibm-content-operator -o jsonpath={.items[0].metadata.name}) -f | grep -v info\n</code></pre> <p>Error messages in the logs would have red color, and typically contain keyword \"failed\", but not all error messages might require followup actions. For monitoring the deployment the best option might be to await the end of the current loop of the Content Operator, and start from reviewing its status, which can easily be viewed from the Openshift Console window. Refer to the Next Exercise for instructions on monitoring the deployment and on required post-deployment activity.</p>"},{"location":"Bring-up/Bring-Up-Lab-2/Exercise-8-PostDeployment/","title":"Exercise 8: Post Deployment Steps / Deployment Verification","text":""},{"location":"Bring-up/Bring-Up-Lab-2/Exercise-8-PostDeployment/#81-introduction","title":"8.1 Introduction","text":"<p>In the previous exercises, the prerequisites for deployment of Cloud Pak For Business Automation have been setup, and a Content-deployment has been started. In this exercise it is shown how to determine, if the deployment is completed, or if errors have happened during the deployment. In the second part, required Post-Deployment steps are performed, and the URLs for usage of ACCE and Content Navigator are extracted from the Openshift Environment.</p>"},{"location":"Bring-up/Bring-Up-Lab-2/Exercise-8-PostDeployment/#82-exercise-instructions","title":"8.2 Exercise Instructions","text":"<ol> <li> <p>Switch to the Firefox window, and login to the Openshift Web Console. Open the Home menu, and select Search. Make sure you use the ibm-cp4ba project. Click on Resources and type in Content. Press return to display all custom resources for the \"Content\" Custom Resource Definition, in project ibm-cp4ba.</p> <p></p> </li> <li> <p>This is displaying the same object as was generated and defined in the last exercise. Click on it. On the lower part of the screen, the conditions of this deployment are listed. The deployment is complete when the row with Type \"Ready\" reaches status \"true\", as outlined below.</p> <p> </p> </li> <li> <p>Open the Workloads section in the menu, and select the Pods menu. There should be 47 pods now in running state, plus some in Completed stages. None should be in Pending or in CrashLoopBackoff state.</p> <p> </p> </li> <li> <p>Open the Configmaps section, and use the filter to display the configmap with the name content-initialization-config. </p> <p></p> </li> <li> <p>Click on it to display its values. When you scroll down, you see that all the settings, cpe_initialized, css_initialized and nav_initialized are set to true. This means, that the initialization of the FileNet Content Platform Domain, and the Content Navigator was successful, i.e. the FileNet Domain and Object Stores were created, the Content Search Server configured, and Content Navigator initialized with Repository connections and Desktops.</p> <p></p> </li> <li> <p>Optionally, for further troubleshooting, use the script deploymentStatus.sh. By right-clicking the Raw  button the script can be saved to a local directory and executed. On a healthy environment it should print following output:</p> </li> </ol> <pre><code>Content CR named content found\nCustom Resource of type Content is applied\n    Running True    Running Running reconciliation\n    Ready        True    Successful\n\nZenService Deployment Progress: 100% (The Current Operation Is Completed)\nZenStatus: zen operator 5.0.2 build 41:  Completed\n    2024-04-08T10:29:32Z Awaiting next reconciliation\n    2024-04-08T11:03:37Z Last reconciliation succeeded\n    2024-04-08T11:03:37Z\n\nFoundation:\n        Running reconciliation\n        Prerequisites execution done.\n\n\n\nInitialization Status:\n{\n        cpe_initialized: True,\n        cpe_os_number: 2,\n        css_initialized: True,\n        nav_initialized: True\n}\n\nIAM Login details: cpadmin / &lt;password&gt;\n</code></pre> <p>The following post-deployment steps described here follow the description in the knowledge center under \"What to do next\": https://www.ibm.com/docs/en/cloud-paks/cp-biz-automation/23.0.2?topic=cpd-option-1-installing-production-deployment-in-openshift-console</p> <ol> <li> <p>Choose the ConfigMaps menu in the Openshift Web Console in section Workloads. In the search box, type in access-info, and find the content-cp4ba-access-info. This is one of the places where you can get the URLs of the deployed CP4BA components. </p> <p>Note that the access info page is one of the resources, those name is derived from the name of the custom resource definition.</p> </li> <li> <p>Next, choose the Secrets menu in the Openshift Web Console in section Workloads. In the search box, search for the secret named platform-auth-idp-credentials.  Click to open the secret, and then click on Reveal values. </p> </li> <li> <p>Still in the Openshift Web Console, open section Networking in the menu and click on entry Routes. Find the route called cpd. It contains the link to the Cloud Pak Dashboard. Right click the link, and select Open in New Private Window. </p> </li> <li> <p>If the environment is configured with self-signed certificates, you will need to accept the security exception (up to two times). Then select IBM provided credentials and login with the credentials from the  platform-auth-idp-credentials secret. </p> <p></p> </li> <li> <p>In the Cloud Pak Dashboard, click on the Manage Users tile</p> <p></p> </li> <li> <p>The Access Control window opens. In the top right corner, there is a link to the Identity Provider Configuration window. There, the identity providers connected to the environment can be selected. Click on it, and note it has two entries, one for the LDAP, and one for the users defined on Openshift. </p> <p></p> </li> <li> <p>Use Browser-Back button to get back to the Access Control. Click the row with the cp4badmin user. </p> <p></p> </li> <li> <p>Click on the Assign roles button. The Assign roles window opens.  Assign all roles to the user, then click on the Assign 4 roles button in bottom right corner.</p> <p></p> </li> <li> <p>Close the private browser window, and open a new one by right clicking on the crd route again, in the Openshift Web Console. Accept the self-signed certificate, if needed.  In the login window, this time select Enterprise LDAP, and supply the administrator username cp4badmin, and password passw0rd with a zero. </p> <p></p> </li> <li> <p>The Cloud Pak Dashboard should open again now, allowing administration access also for the  cp4badmin user. Verify that the Manage Users tile is still visible.</p> <p></p> </li> <li> <p>Leave the private browser window open, and get back to the Openshift Web Console. In the Openshift Web Console, choose menu entry Installed Operators from the Operators section.  Click on the Name of the CP4BA FileNet Content Manager Operator. </p> <p></p> </li> <li> <p>The Operator page opens. Select the All Instances tab. Here you see an alternative for checking on the deployment status. When the deployment is ready, the status column will contain the Condition Ready.</p> <p></p> </li> <li> <p>Click on the content link. The CP4BA FileNet Content Manager Deployment overview window opens. It lists the configuration made previously through the Custom Resource Definition, and also includes links to the components.</p> <p></p> </li> <li> <p>Copy the link to ACCE into the clipboard (right-click and invoke Copy Link), and paste it in the Private Window\u2019s URL entry. The ACCE link has the name \"CPE Login URL\" in the list.</p> <p>No login should be needed, as the environment uses single sign-on through the Cloud Paks Identity Provider. In the opened ACCE window, verify that both Object Stores have been defined. </p> <p>Note: At this step you can investigate a bit yourself and look around. Determine for example if an Advanced Storage Area and an Index Area have been defined for the Object Stores.</p> </li> <li> <p>In the Openshift Web Console, copy the link to the Content Navigator. There are two, only the one with the name Navigator Login URL for CP4BA works. The other link is intended for other deployment types. Paste the link again into the Private Windows URL entry box (right click and select \"Paste and Go\")</p> </li> </ol> <p>Again, login will be skipped, and the Content Navigator desktop is shown. To arrive at the Administration feature, use the Hamburger menu in top left corner. Review that repository definitions for the two object stores have been created and that Desktop definitions have been made.</p> <p>Congratulations, at this stage the deployment of the Cloud Pak For Business Automation is has been completed, and the environment could be handed over to a customer. </p>"},{"location":"Business%20Automation%20Application/","title":"IBM Business Automation Application","text":""},{"location":"Business%20Automation%20Application/#overview","title":"Overview","text":"<p>This is a low-code capability of IBM Cloud Pak for Business Automation that let's business users leverage services built by developers in other parts of the platform such as Workflow, Decisions &amp; Content. </p>"},{"location":"Business%20Automation%20Application/#labs","title":"Labs","text":"<p>Track 2 - Developer Role / Solution Implementation</p> <ul> <li>Introduction to IBM Business Automation Application: This lab introduces you to the key concepts of IBM Business Automation Application including Application Designer. In this you will learn how to create toolkits, templates and applications that integrate with the Worklow, Decisions &amp; Content capabilitities of the CP4BA platform.</li> </ul> <p>Approximate Duration: 2 Hours</p>"},{"location":"Business%20Automation%20Insights/","title":"IBM Business Automation Insights","text":""},{"location":"Business%20Automation%20Insights/#overview","title":"Overview","text":"<p>IBM Business Automation Insights (BAI) is a cloud capability to capture end to end business data (events) from Cloud Pak for Automation (CP4A) platform components to operational data store and long-term store (data lake).  BAI provides real-time operational visibility to Business Managers via custom or pre-built set of dashboards. Custom dashboards can be built by IT (using Kibana) or business users (using Business Performance Center). The data collected by BAI and stored in the data lake can be used to inject AI into CP4A platform, for example it can be used to make recommendations to business managers and knowledge workers. Business Performance Center is a no-code monitoring application native to IBM Business Automation Insights. You can design and share dashboards in minutes that capture business data in near real time and provide real time awareness of important business activities and processes.</p>"},{"location":"Business%20Automation%20Insights/#labs","title":"Labs","text":"<p>Track 2 - Developer Role / Solution Implementation</p> <ul> <li>Build Business Performance Center Dashboards: In the lab, you will learn how to build and use Business Performance Center dashboards to provide insights into a Client Onboarding workflow solution for line of business users.</li> </ul> <p>Approximate Duration: 1 Hour</p>"},{"location":"Content/","title":"IBM FileNet Content Services","text":""},{"location":"Content/#overview","title":"Overview","text":"<p>IBM FileNet Content Services is a flexible, full-featured content management solution that provides the foundation for IBM Cloud Pak\u00ae for Business Automation. In labs you will get introduced to important core concepts of FileNet Content Platform Engine and Content Services GraphQL and IBM Content Navigator which will enable you to use FileNet Content Platform Engine to build the information architecture for automation projects realized with Cloud Pak for Business Automation. </p>"},{"location":"Content/#labs","title":"Labs","text":"<p>Track 2 - Developer Role / Solution Implementation</p> <ul> <li>Setting up FileNet Content Manager for Automation Projects on Cloud Pak for Business Automation:   In this lab, you will create a small hierarchy of Document classes to   capture different kinds of documents together with custom metadata,   and will learn about the most important security concepts. You will   explore Document storage and learn to migrate documents between   different Storage Areas.  Further you will determine how to trigger   custom actions for example when new documents have arrived, and how to   configure and test functionality of content based retrieval,   i.e. searches for documents based on information contained in the   documents themselves, not (only) on their metadata.</li> </ul> <p>On this lab, for triggering the custom actions, a custom javascript is   used to file a newly uploaded document into a folder, those identity   is derived from a search. The script is available in the Lab Data folder. Be aware that in the script, some   replacements need to be made, to make it refer to the right   properties. The username prefix is denoted by usrxxx in the script,   and the xxx part needs to be updated.</p> <p>Approximate Duration: 4 - 5 hours</p> <ul> <li>Interfacing FileNet Content Platform Engine with GraphQL on Cloud Pak for Business Automation:   The second lab on GraphQL builds on top of the first one, as the   searches performed using GraphQL use the documents and document   classes defined in the first lab.  Here you learn by a series of   example, how to build the most important queries using GraphQL.  The   examples also show how to download documents using GraphQL, how to   create folders, and modify security settings.</li> </ul> <p>Approximate Duration: 1.5 - 2 hours</p> <ul> <li>Content Navigator on Cloud Pak for Business Automation:   The third lab on IBM Content Navigator builds on top of the first, but not the second one.   In it you can learn important concepts which allow you to configure IBM Content Navigator for a business application.   The administration parts of the lab cannot be performed in the context of the shared lab environment of the JAM, and   are provided as Walkthroughs in the lab guide.</li> </ul> <p>Approximate Duration: 1.5 - 2 hours</p>"},{"location":"Decisions/","title":"Automation Decision Services","text":""},{"location":"Decisions/#overview","title":"Overview","text":"<p>Part of the IBM Cloud Pak\u00ae for Business Automation platform, IBM Automation Decision Services provides a comprehensive environment for authoring, managing, and running decision services. Business experts can infuse intelligence into business decisions by combining decision models and predictive models into decision services. Business decisions can be published as Automation Services and easily consumed from other capability of the platform such as Workflow.</p>"},{"location":"Decisions/#labs","title":"Labs","text":"<p>Track 2 - Developer Role / Solution Implementation</p> <ul> <li>Manage Decisions and Infuse Machine Learning </li> </ul> <p>This Lab introduces you to the key concepts of IBM Business Automation Decision Services. It includes 3 exercises that can be done individually. In this Lab you learn how to model business decisions, infuse intelligence by adding a predictive model, share and publish decision services.</p> <p>Approximate Duration: 3 hours</p>"},{"location":"Document%20Processing/","title":"IBM Automation Document Processing","text":""},{"location":"Document%20Processing/#overview","title":"Overview","text":"<p>Automation Document Processing provides the capabilities that help you build an AI-powered data enrichment tool for document processing and storage.</p> <p>Manual document processing is a major obstacle for many enterprises, bringing digital transformation initiatives to a halt and demanding time and resources. With the amount of data and documents continuing to grow exponentially, it\u2019s more important than ever to automate your document processing. IBM Automation Document Processing combines AI and deep learning with low code tooling to help you design, configure, and deploy a solution for document classification and data extraction.</p> <p>Labor-intensive manual processing of documents is instead handled by the document processing application. The document processing user can quickly catch and correct issues on documents or batches of documents that have already been categorized and extracted. And when the processing completes, your documents and your data are stored and ready for use by downstream applications.</p>"},{"location":"Document%20Processing/#note","title":"NOTE","text":"<p>Use the self-reservation option with the below TechZone Reservation URL.</p>"},{"location":"Document%20Processing/#techzone-reservation-url","title":"TechZone Reservation URL","text":"<p>To get a TechZone Reservation click here</p> <p>Note: Self-reservation might take minimum 2-3 hours of time for provisioning the environment on IBM TechZone and are ready to use for ADP lab</p>"},{"location":"Document%20Processing/#labs","title":"Labs","text":"<p>Set up a capture solution in minutes with IBM Automation Document Processing. In this session, students will configure their own capture project. They will learn how to use machine learning classification for their sample documents, define fields for extraction, create validation rules, and use deep learning* (subject to environment configuration) to automate data extraction. </p> <p>Introduce the no- or low-code application building capabilities of Application Designer based on your Document Processing project to create a document processing end-user application. This application recognizes your documents, extracts your relevant data, and presents issues to fix before sending the documents to storage and using the data in other system</p> <p>Approximate Duration: 3-4 Hours</p>"},{"location":"Document%20Processing/#download","title":"Download","text":"<p>Lab documentation - needed to run lab.</p> <p>Download the three Zip files from github lab data - Lab Data these will used in the lab.  Unzip the files on your laptop</p>"},{"location":"IBM%20Cloud%20Pak%20for%20Business%20Automation%20%28End-to-End%29/","title":"IBM Cloud Pak for Business Automation","text":""},{"location":"IBM%20Cloud%20Pak%20for%20Business%20Automation%20%28End-to-End%29/#overview","title":"Overview","text":"<p>IBM Cloud Pak\u00ae for Business Automation offers design, build, run, and automation services to rapidly scale your programs and fully execute and operationalize an automation strategy.</p>"},{"location":"IBM%20Cloud%20Pak%20for%20Business%20Automation%20%28End-to-End%29/#labs","title":"Labs","text":"<p>Track 1 - Foundation</p> <ul> <li>IBM Cloud Pak for Business Automation: An End-to-End Demonstration: This lab showcases the art of the possible for the IBM Cloud Pak for Business Automation platform. You will assume the role of an end user to step through an integrated Client Onboarding scenario. Approximate Duration: 2 hours</li> </ul>"},{"location":"Process%20Mining/","title":"Process Mining","text":""},{"location":"Process%20Mining/#overview","title":"Overview","text":"<p>Process Mining is a family of techniques in process management that supports the analysis of actual business processes based on event logs. During process mining, specialized data mining algorithms are applied to identify trends, patterns, and details in event logs recorded by an information system. Process mining aims to improve process efficiency and understanding.</p> <p>Task Mining is the discovery, monitoring, and analysis of user interaction data on desktops through the recording of frontend activities.  </p>"},{"location":"Process%20Mining/#labs","title":"Labs","text":""},{"location":"Process%20Mining/#track-2-developer-role-solution-implementation","title":"Track 2 - Developer Role / Solution Implementation","text":"<p>Client Onboarding \u2013 identification of workflow automation process improvement opportunities: Use Process Mining to Get Insights into Client Onboarding Workflow </p> <p>Approximate Duration: 1 hour 30 Minutes</p> <p>Click here to try other labs not featured in this event!</p>"},{"location":"Robotic%20Process%20Automation/","title":"IBM Robotic Process Automation","text":""},{"location":"Robotic%20Process%20Automation/#overview","title":"Overview","text":"<p>Going from simple, back-office task automation to scaled automation to handle time-consuming business processes can be a challenge. The IBM\u00ae Robotic Process Automation offering helps you automate more business and IT processes at scale with the ease and speed of traditional RPA. Software robots, or bots, can act on AI insights to complete tasks with no lag time and enable you to achieve digital transformation.            </p>"},{"location":"Robotic%20Process%20Automation/#labs","title":"Labs","text":"<p>Developer Role / Solution Implementation</p> <ul> <li>Application Automation using IBM RPA: In this lab you will learn how to use IBM RPA Studio to develop a bot to automate a Java swing application and a web application. </li> <li>IBM RPA and Workflow Integration: In this lab you will learn how the bot designed in RPA Studio can easily be integrated into a business process developed with the Workflow capability in IBM Cloud Pak for Business Automation.</li> <li>Orchestrating scripts in IBM RPA: In this lab you will learn how to create and use the orchestration process, message queues capability of serving messages of multiple customers automating the customer and service registration process divided into three steps.</li> <li>Exception Handling scripts in IBM RPA: In this lab you will walk through the process of applying exception handling along with best practices. You will automate the sales lead and claims submission process using error handling. The same will be divided into micro scenarios which will cover the business and system exceptions.</li> </ul> <p>The labs requires an IBM RPA environment which can be reserved here. Once you have reserved an environment, you will receive a link to the environment via email. </p>"},{"location":"Solutions/Client%20Onboarding/","title":"Jam-in-a-Box - Single User Environment for CP4BA 23.0.2","text":"<p>[!IMPORTANT]</p> <ul> <li>As this approach relies on reserving an environment from IBM TechZone, this document is only applicable to IBM Business Partners that have the ability to request environments from TechZone and IBMers. </li> <li>In addition, to use this environment, accessing the bastion host via RDP is required. Ensure you have an RDP tool of choice for your operating system.</li> <li>At this point it is not possible to configure RPA as part of the Client Onboarding scenario.</li> </ul> <p>If you have your own Cloud Pak for Business Automation (CP4BA) 23.0.2 environment, can't use RDP, or need the RPA bot in action, please refer to this document and this document for other options.</p>"},{"location":"Solutions/Client%20Onboarding/#quick-start","title":"Quick Start","text":"<ol> <li>Reserve and prepare the Jam-in-a-Box environment as described in the section below</li> <li>Read the Lab Considerations section for specifics of using the labs in the context of this Jam-in-a-Box environment</li> <li>Follow the link to the documentation of the lab you want to perform in the Lab Instructions section</li> </ol>"},{"location":"Solutions/Client%20Onboarding/#overview","title":"Overview","text":"<p>This Jam-in-a-Box environment is provided to you by the IBM Business Automation and Digital Labor SWAT team.</p> <p>The major benefits of using this environment are:</p> <ul> <li>Provisioning time is only 2-3 hours</li> <li>Client Onboarding scenario and lab artifacts are pre-deployed for you</li> <li>All links and user credentials are stored for you in Firefox</li> </ul> <p>Based on the technology used to achieve a short provisioning time, you need to perform a few simple steps before you can use the environment.</p> <p>What's included:</p> <ul> <li>Red Hat OpenShift (OCP 4.12) on VMWare on IBM Cloud</li> <li>IBM Cloud Pak for Business Automation 23.0.2 IF002</li> </ul>"},{"location":"Solutions/Client%20Onboarding/#reserve-and-prepare-the-jam-in-a-box-single-user-environment","title":"Reserve and Prepare the Jam-in-a-Box Single User Environment","text":"<ol> <li> <p>Reserve your environment on IBM TechZone from the IBM Cloud Pak for Business Automation and Digital Labor - Jam-in-a-Box collection by clicking on the Jam in a Box - Single-User tile</p> <p>On the Create a reservation page make the following selections:</p> <ul> <li>Purpose: e.g. Education</li> <li>Purpose description: Enter any text Tip: The selection you make here determines if you need to specify a 'Sales Opportunity number' and the 'reservation policy' (how long the environment is available and how often it can be extended).</li> <li>Preferred Geography: Select the geography that is closest to you.  Remark: Depending on available capacity the deployment have been seen to fail sometimes. Please request another environment, potentially selecting a different geography.</li> <li>End date and time: Should get populated automatically. No changes needed.</li> <li>Accept the terms and conditions: In the lower right corner, check the box </li> <li>Submit</li> </ul> </li> <li> <p>Wait till the environment is Ready, this will normally take between 2-3 hours</p> </li> <li> <p>Once your environment is Ready, connect to the bastion host through RDP (open the reserved environment from https://techzone.ibm.com/my/reservations and copy the RDP value at the top to your RDP tool)    Important: The credentials to login to the bastion host are mention in the description of the tile</p> </li> <li> <p>From within the bastion host</p> <ol> <li>Open Firefox using the icon on the desktop</li> <li>Open the Red Hat OpenShift console by clicking the Red Hat OpenShift bookmark</li> <li>Login to the Red Hat OpenShift console using the credentials for the user ocadmin that are stored in Firefox</li> <li>Copy the login command to the clipboard       (Under \"ocadmin\" in the top right corner click Copy login command, a new tab opens, log in again using ocadmin, click Display Token, and then copy the entire line under Log in with this token)</li> <li>Open a Terminal using the respective icon on the desktop, paste the content from the clipboard (right click on the Terminal window, then select \"Paste\"), and press Enter to login to your Red Hat OpenShift cluster from the command line</li> <li>Type ./31-prepareJiaB4usage.sh (including the dot) at the beginning) and press Enter to execute the script that prepares the environment for usage</li> <li>When the script asks you if you want to continue, enter y (or Y or Yes or YES) and press Enter</li> <li>Once the script completes, your environment is ready to be used for the supported labs. Follow the respective lab instructions for the next steps</li> </ol> </li> </ol> <p>[!IMPORTANT]</p> <p>It might happen that:</p> <ul> <li>the login does not work, or shows \"Error 502 - Bad Gateway\". In this case please wait for some more time (about 15 minutes), then the log-in should work and the requested page is shown</li> <li>the login results in \"404 Page not found\" error.  In this case please wait for some more time, then the log-in should work and the requested page is shown</li> </ul> <p>These issues are the result of restarting some pods, which may take a different amount of time depending on the resources available on TechZone.</p>"},{"location":"Solutions/Client%20Onboarding/#labs-instructions-considerations","title":"Labs Instructions &amp; Considerations","text":""},{"location":"Solutions/Client%20Onboarding/#lab-considerations","title":"Lab Considerations","text":"<p>The lab instructions are written in context of a Tech Jam event. When performing the labs as part of Jam-in-a-Box keep in mind:</p> Lab instructions mention... As part of this Jam-in-a-Box environment... using the URLs found on the Tech Jam event page please use the bookmarks created for you in Firefox how to receive your user credentials using a link on the Tech Jam event page please use the credentials stored within Firefox for either the admin user cp4badmin or the business user usr001 to prefix your artifacts with \"usrXYZ\" you may choose to still follow the instructions in this point, even when this is not strictly required as this is a single-user environment <p>[!TIP]</p> <p>Initially the environment may appear a little slow. Once the components have warmed up, it should perform reasonably well.</p>"},{"location":"Solutions/Client%20Onboarding/#lab-instructions","title":"Lab Instructions","text":"<p>Below you find the links to the lab instructions for the labs supported in this environment:</p> <ul> <li>IBM Cloud Pak for Business Automation (End-to-End)</li> <li>IBM Business Automation Application</li> <li>IBM Automation Decision Services</li> <li>IBM Automation Document Processing</li> <li>IBM Business Automation Insights</li> <li>IBM Business Automation Workflow</li> <li>IBM FileNet Content Services (CPE, GraphQL &amp; Navigator)</li> </ul>"},{"location":"Solutions/Client%20Onboarding/#support","title":"Support","text":"<p>We aim to support successfully utilizing our Jam-in-a-Box.</p> <p>Business Partners (require an invitation) and IBMers</p> <p>To engage us, drop us a message at #jam-in-a-box-ba-dl.</p> <p>All others</p> <p>For anyone who doesn\u2019t fall into the business partner or IBM employee category, please feel free to open a new issue on our GitHub repository. We\u2019ll be more than happy to address your questions and concerns there.</p>"},{"location":"Solutions/Client%20Onboarding/#disclaimer","title":"Disclaimer","text":"<p>The information, tools, and artifacts describes and linked are provided AS-IS and without any warranty. Please also refer to the license that is part of this repository for details.</p>"},{"location":"Solutions/Client%20Onboarding/README_2202/","title":"Jam-in-a-Box - Client Onboarding for CP4BA 22.0.2","text":""},{"location":"Solutions/Client%20Onboarding/README_2202/#quick-start","title":"Quick Start","text":"<ol> <li>Select the lab(s) you want to do from the table in the Labs section below</li> <li>Follow the instructions for the lab(s) in right column to get and prepare the required environment(s)</li> <li>Read the Lab Considerations section for specifics of using the labs in the context of Jam-in-a-Box</li> <li>Follow the link(s) to the documentation of the lab(s) in the left column and perform the lab(s)</li> </ol>"},{"location":"Solutions/Client%20Onboarding/README_2202/#overview","title":"Overview","text":"<p>Introduction of the Client Onboarding solution and solution exports: https://github.com/IBM/cp4ba-client-onboarding-scenario </p> <p>Lab assets: The solution has nine hands-on labs associated with it</p> <p>Jam-in-a-Box environment: In order to use the solution in your own Jam-in-a-Box environment, deploy the Client Onboarding solution and labs as described in this document. The document also contains hints in case you don't have access to/can't get an IBM TechZone environment.</p> <p>What's included:</p> <ul> <li>Red Hat OpenShift (OCP 4.12) on VMWare on IBM Cloud</li> <li>IBM Cloud Pak for Business Automation 22.0.2 IF005</li> <li>IBM Process Mining 1.14.1</li> <li>IBM Robotic Process Automation 23.0.2</li> </ul>"},{"location":"Solutions/Client%20Onboarding/README_2202/#labs","title":"Labs","text":"<p>Most labs are accessible using the Jam-in-a-Box environment. For some labs, you will need a separate environment. The table below provides the respective details:</p> <p>Mapping of labs to environments</p> Lab(s) Environment (IBM TechZone - Business Partners and IBMers only) IBM Cloud Pak for Business Automation (End-to-End)IBM Business Automation ApplicationIBM Business Automation InsightsIBM FileNet Content Services (CPE, GraphQL &amp; Navigator)IBM Automation Decision ServicesIBM Business Automation Workflow Jam-in-a-Box environment (deployment instructions are available in this document) IBM Process Mining Follow the instructions provided on the respective lab overview page IBM Robotic Process Automation Follow the instructions provided on the respective lab overview page"},{"location":"Solutions/Client%20Onboarding/README_2202/#lab-considerations","title":"Lab Considerations","text":"<ul> <li>The lab instructions refer to using the URLs found on the Tech Jam event page. For Jam-in-a-Box environments, please use those URLs provided when the deployment completes and/or refer to the <code>client-onboarding-information</code> ConfigMap that is created when the deployment is successful.</li> <li>The lab instructions mention how to receive your user credentials using a link on the Tech Jam event page. For Jam-in-a-Box environments, please use the admin user and admin password (or one of the business users) provided when the deployment completes and/or refer to the <code>client-onboarding-information</code> ConfigMap that is created when the deployment is successful.</li> <li>The lab instructions mostly mention to prefix your artifacts with \"usrXYZ\". This is important when working in a shared environment. You may choose to still follow the instructions in this point, even when this is not strictly required for the Jam-in-a-Box environment that is normally considered a single-user environment.</li> </ul>"},{"location":"Solutions/Client%20Onboarding/README_2202/#support","title":"Support","text":"<p>We aim to support successfully utilizing our Jam-in-a-Box.</p> <p>Business Partners (require an invitation) and IBMers</p> <p>To engage us, drop us a message at #jam-in-a-box-ba-dl.</p> <p>All others</p> <p>For anyone who doesn\u2019t fall into the business partner or IBM employee category, please feel free to open a new issue on our GitHub repository. We\u2019ll be more than happy to address your questions and concerns there.</p>"},{"location":"Solutions/Client%20Onboarding/README_2202/#disclaimer","title":"Disclaimer","text":"<p>The information, tools, and artifacts describes and linked are provided AS-IS and without any warranty. Please also refer to the license that is part of this repository for details.</p>"},{"location":"Solutions/Client%20Onboarding/README_2301/","title":"Jam-in-a-Box - Client Onboarding for CP4BA 23.0.1","text":""},{"location":"Solutions/Client%20Onboarding/README_2301/#quick-start","title":"Quick Start","text":"<ol> <li>Select the lab(s) you want to do from the table in the Labs section below</li> <li>Follow the instructions for the lab(s) in right column to get and prepare the required environment(s)</li> <li>Read the Lab Considerations section for specifics of using the labs in the context of Jam-in-a-Box</li> <li>Follow the link(s) to the documentation of the lab(s) in the left column and perform the lab(s)</li> </ol>"},{"location":"Solutions/Client%20Onboarding/README_2301/#overview","title":"Overview","text":"<p>Introduction of the Client Onboarding solution and solution exports: https://github.com/IBM/cp4ba-client-onboarding-scenario </p> <p>Lab assets: The solution has ten hands-on labs associated with it</p> <p>Jam-in-a-Box environment: In order to use the solution in your own Jam-in-a-Box environment, deploy the Client Onboarding solution and labs as described in this document. The document also contains hints in case you don't have access to/can't get an IBM TechZone environment.</p> <p>What's included:</p> <ul> <li>Red Hat OpenShift (OCP 4.12) on VMWare on IBM Cloud</li> <li>IBM Cloud Pak for Business Automation 23.0.1 IF001</li> <li>IBM Process Mining 1.14.1</li> <li>IBM Robotic Process Automation 23.0.2</li> </ul>"},{"location":"Solutions/Client%20Onboarding/README_2301/#labs","title":"Labs","text":"<p>Most labs are accessible using the Jam-in-a-Box environment. For some labs, you will need a separate environment. The table below provides the respective details:</p> <p>Mapping of labs to environments</p> Lab(s) Environment (IBM TechZone - Business Partners and IBMers only) IBM Cloud Pak for Business Automation (End-to-End)IBM Business Automation ApplicationIBM Business Automation InsightsIBM FileNet Content Services (CPE, GraphQL &amp; Navigator)IBM Automation Decision ServicesIBM Business Automation Workflow Jam-in-a-Box environment (deployment instructions are available in this document) IBM watsonx Orchestrate Jam-in-a-Box environment (deployment instructions are available in this document)Access to an watsonx Orchestrate instance is required as an additional prerequisite. Please check the watsonx Orchestrate content on Seismic to learn how to get access to such an instance. IBM Process Mining Follow the instructions provided on the respective lab overview page IBM Robotic Process Automation Follow the instructions provided on the respective lab overview page"},{"location":"Solutions/Client%20Onboarding/README_2301/#lab-considerations","title":"Lab Considerations","text":"<ul> <li>The lab instructions refer to using the URLs found on the Tech Jam event page. For Jam-in-a-Box environments, please use those URLs provided when the deployment completes and/or refer to the <code>client-onboarding-information</code> ConfigMap that is created when the deployment is successful.</li> <li>The lab instructions mention how to receive your user credentials using a link on the Tech Jam event page. For Jam-in-a-Box environments, please use the admin user and admin password (or one of the business users) provided when the deployment completes and/or refer to the <code>client-onboarding-information</code> ConfigMap that is created when the deployment is successful.</li> <li>The lab instructions mostly mention to prefix your artifacts with \"usrXYZ\". This is important when working in a shared environment. You may choose to still follow the instructions in this point, even when this is not strictly required for the Jam-in-a-Box environment that is normally considered a single-user environment. For the watsonx Orchestrate lab you should still do this as you are probably working on a shared watsonx Orchestrate instance with other users. </li> </ul>"},{"location":"Solutions/Client%20Onboarding/README_2301/#support","title":"Support","text":"<p>We aim to support successfully utilizing our Jam-in-a-Box.</p> <p>Business Partners (require an invitation) and IBMers</p> <p>To engage us, drop us a message at #jam-in-a-box-ba-dl.</p> <p>All others</p> <p>For anyone who doesn\u2019t fall into the business partner or IBM employee category, please feel free to open a new issue on our GitHub repository. We\u2019ll be more than happy to address your questions and concerns there.</p>"},{"location":"Solutions/Client%20Onboarding/README_2301/#disclaimer","title":"Disclaimer","text":"<p>The information, tools, and artifacts describes and linked are provided AS-IS and without any warranty. Please also refer to the license that is part of this repository for details.</p>"},{"location":"Solutions/Client%20Onboarding/README_2302_ApolloBA_CP4BADemos/","title":"CP4BA Demos Environment based on Apollo Business Automation/Cloud Pak Deployer for CP4BA 23.0.2","text":"<p>[!IMPORTANT]</p> <ul> <li>As this approach relies on reserving an environment from IBM TechZone, this document is only applicable to IBM Business Partners that have the ability to request environments from TechZone and IBMers. </li> <li>The RPA part of the Client Onboarding scenario is not configured.</li> </ul> <p>If you have your own Cloud Pak for Business Automation (CP4BA) 23.0.2 environment or need the RPA bot in action, please refer to this document for other options.</p>"},{"location":"Solutions/Client%20Onboarding/README_2302_ApolloBA_CP4BADemos/#quick-start","title":"Quick Start","text":"<ol> <li>Reserve a CP4BA Demos environment as described in the section below</li> <li>Read the Lab Considerations section for specifics of using the labs in the context of this CP4BA Demos environment</li> <li>Follow the link to the documentation of the lab you want to perform in the Lab Instructions section</li> </ol>"},{"location":"Solutions/Client%20Onboarding/README_2302_ApolloBA_CP4BADemos/#overview","title":"Overview","text":"<p>This Jam-in-a-Box environment is provided to you as a cooperation between the owners of the Apollo Business Automation approach and the IBM Business Automation and Digital Labor SWAT team.</p> <p>The major benefits of using this environment are:</p> <ul> <li>Environment can be used for a single-user use case and for running mini-Tech Jams with approximately 10 participants (feedback welcome if you used it more users)</li> <li>Client Onboarding scenario and lab artifacts are pre-deployed for you</li> <li>20 business users have been created that can be given to participants of a mini-Tech Jam</li> </ul> <p>[!CAUTION]</p> <p>It can take 5-7 hours until the environment is available.</p>"},{"location":"Solutions/Client%20Onboarding/README_2302_ApolloBA_CP4BADemos/#reserve-the-cp4ba-demos-environment","title":"Reserve the CP4BA Demos Environment","text":"<p>Follow the journey Apollo Business Automation - CP4BA Demos to reserve your environment on IBM TechZone. It consists of three major steps:</p> <ol> <li>Requesting the environment in step 1 and waiting till the environment is Ready and fully deployed. This will normally take approximately 5-7 hours.</li> <li>Validating the successful deployment of the Cloud Pak for Business Automation as described in step 2.</li> <li>Validating the successful deployment of the Client Onboarding scenario assets as described in step 3.</li> </ol>"},{"location":"Solutions/Client%20Onboarding/README_2302_ApolloBA_CP4BADemos/#labs-instructions-considerations","title":"Labs Instructions &amp; Considerations","text":""},{"location":"Solutions/Client%20Onboarding/README_2302_ApolloBA_CP4BADemos/#lab-considerations","title":"Lab Considerations","text":"<p>The lab instructions are written in context of a Tech Jam event. When performing the labs as part of Jam-in-a-Box keep in mind:</p> Lab instructions mention... As part of this Jam-in-a-Box environment... using the URLs found on the Tech Jam event page please login to the OpenShift console, go to Workloads -&gt; ConfigMaps and search for client-onboarding-information.The ConfigMap contains all relevant URLs for this environment. For a mini-Tech Jam share them with the participants in a suitable form. how to receive your user credentials using a link on the Tech Jam event page please login to the OpenShift console, go to Workloads -&gt; ConfigMaps and search for client-onboarding-information.The ConfigMap contains all relevant user names and password for this environment.For a mini-Tech Jam share a dedicated user name and password with each participants in a suitable form. to prefix your artifacts with \"usrXYZ\" depending on if you use the environment as a single-user environment or for running a mini-Tech Jam, you may choose to follow the instructions in this point"},{"location":"Solutions/Client%20Onboarding/README_2302_ApolloBA_CP4BADemos/#lab-instructions","title":"Lab Instructions","text":"<p>Below you find the links to the lab instructions for the labs supported in this environment:</p> <ul> <li>IBM Cloud Pak for Business Automation (End-to-End)</li> <li>IBM Business Automation Application</li> <li>IBM Automation Decision Services</li> <li>IBM Automation Document Processing (only for single-user usage)</li> <li>IBM Business Automation Insights</li> <li>IBM Business Automation Workflow</li> <li>IBM FileNet Content Services (CPE, GraphQL &amp; Navigator)</li> <li>IBM watsonx Orchestrate (requires a separate watsonX Orchestrate SaaS tenant)</li> </ul>"},{"location":"Solutions/Client%20Onboarding/README_2302_ApolloBA_CP4BADemos/#support","title":"Support","text":"<p>We aim to support successfully utilizing our assets as part of Jam-in-a-Box. For questions and issues around Apollo Business Automation, please reach out to its authors. </p> <p>For questions and issues around the Client Onboarding labs:</p> <p>Business Partners (require an invitation) and IBMers</p> <p>To engage us, drop us a message at #jam-in-a-box-ba-dl.</p> <p>All others</p> <p>For anyone who doesn\u2019t fall into the business partner or IBM employee category, please feel free to open a new issue on our GitHub repository. We\u2019ll be more than happy to address your questions and concerns there.</p>"},{"location":"Solutions/Client%20Onboarding/README_2302_ApolloBA_CP4BADemos/#disclaimer","title":"Disclaimer","text":"<p>The information, tools, and artifacts describes and linked are provided AS-IS and without any warranty. Please also refer to the license that is part of this repository for details.</p>"},{"location":"Solutions/Client%20Onboarding/README_2302_SelfDeploy/","title":"Jam-in-a-Box - Client Onboarding for CP4BA 23.0.2/watsonX Orchestrate - Deploying the Assets Yourself","text":""},{"location":"Solutions/Client%20Onboarding/README_2302_SelfDeploy/#quick-start","title":"Quick Start","text":"<ol> <li>Read the Lab Considerations section for specifics of using the labs in the context of Jam-in-a-Box</li> <li>Select the lab(s) you want to do from the table in the Mapping of labs to environments section below</li> <li>Follow the instructions for the lab(s) in the right column to get and prepare the required environment(s)</li> <li>Follow the link(s) to the documentation of the lab(s) in the left column and perform the lab(s)</li> </ol>"},{"location":"Solutions/Client%20Onboarding/README_2302_SelfDeploy/#overview","title":"Overview","text":"<p>This type of Jam-in-a-Box approach provides you with the largest flexibility to deploy the Client Onboarding assets to the environment of your choice. It is provided to you by the IBM Business Automation and Digital Labor SWAT team through the deployment tool.</p> <p>The major benefits of using this environment are:</p> <ul> <li>Independent of CP4BA environment provisioned by TechZone, but supporting TechZone provisioned environments</li> <li>Full flexibility in which pieces of the Client Onboarding scenario and labs to be deployed and with which options</li> </ul> <p>Introduction to the Client Onboarding solution and solution exports: https://github.com/IBM/cp4ba-client-onboarding-scenario </p> <p>Jam-in-a-Box environment: In order to use the solution in your own Jam-in-a-Box environment, deploy the Client Onboarding solution and labs as described in this document for a Starter deployment or refer to this document for Enterprise deployments.</p>"},{"location":"Solutions/Client%20Onboarding/README_2302_SelfDeploy/#labs","title":"Labs","text":""},{"location":"Solutions/Client%20Onboarding/README_2302_SelfDeploy/#lab-considerations","title":"Lab Considerations","text":"<p>The lab instructions are written in context of a Tech Jam event. When performing the labs as part of Jam-in-a-Box keep in mind:</p> Lab instructions mention... As part of this Jam-in-a-Box environment... using the URLs found on the Tech Jam event page please use those URLs provided when the deployment completes and/or refer to the <code>client-onboarding-information</code> ConfigMap that is created when the deployment is successful how to receive your user credentials using a link on the Tech Jam event page please use the admin user and admin password (or one of the business users) provided when the deployment completes and/or refer to the <code>client-onboarding-information</code> ConfigMap that is created when the deployment is successful to prefix your artifacts with \"usrXYZ\" this is important when working in a shared environment. You may choose to still follow the instructions in this point, even when this is not strictly required for the Jam-in-a-Box environment (at least if a Starter pattern environment) that is normally considered a single-user environment. For the watsonx Orchestrate lab you should still do this as you are probably working on a shared watsonx Orchestrate instance with other users."},{"location":"Solutions/Client%20Onboarding/README_2302_SelfDeploy/#mapping-of-labs-to-environments","title":"Mapping of labs to environments","text":"Lab(s) Environment (IBM TechZone - Business Partners and IBMers only) IBM Cloud Pak for Business Automation (End-to-End)IBM Automation Decision ServicesIBM Automation Document ProcessingIBM Business Automation ApplicationIBM Business Automation InsightsIBM Business Automation WorkflowIBM FileNet Content Services (CPE, GraphQL &amp; Navigator) Jam-in-a-Box environment (deployment instructions are available in this document for Starter pattern, or this document for Enterprise pattern) IBM watsonx Orchestrate Jam-in-a-Box environment (deployment instructions are available in this document for Starter pattern, or this document for Enterprise pattern)Access to a watsonx Orchestrate instance is required as an additional prerequisite. Please check the watsonx Orchestrate content on Seismic to learn how to get access to such an instance."},{"location":"Solutions/Client%20Onboarding/README_2302_SelfDeploy/#support","title":"Support","text":"<p>We aim to support successfully utilizing our Jam-in-a-Box.</p> <p>Business Partners (require an invitation) and IBMers</p> <p>To engage us, drop us a message at #jam-in-a-box-ba-dl.</p> <p>All others</p> <p>For anyone who doesn\u2019t fall into the business partner or IBM employee category, please feel free to open a new issue on our GitHub repository. We\u2019ll be more than happy to address your questions and concerns there.</p>"},{"location":"Solutions/Client%20Onboarding/README_2302_SelfDeploy/#disclaimer","title":"Disclaimer","text":"<p>The information, tools, and artifacts describes and linked are provided AS-IS and without any warranty. Please also refer to the license that is part of this repository for details.</p>"},{"location":"Workflow/","title":"IBM Business Automation Workflow","text":""},{"location":"Workflow/#overview","title":"Overview","text":"<p>IBM Business Automation Workflow is software that combines business process management and case management  capabilities in a single integrated workflow solution. It unites information process, and users to provide a 360-degree view of work to help drive more successful business outcomes.</p>"},{"location":"Workflow/#labs","title":"Labs","text":"<p>Track 2 - Developer Role / Solution Implementation</p> <ul> <li>Introduction to IBM Business Automation Workflow: This lab showcases how you can create a sample Workflow project using Case features. It covers Case &amp; Process integration and building UIs using Coaches.</li> </ul> <p>Approximate Duration: 3-4 hours</p> <ul> <li>Consume &amp; Publish Automation Services in Workflow: This lab showcases how you can consume capabilities from the IBM Automation platform using Automation Services. You will also create an external service to invoke a Java app that sends out emails. Finally, you will learn how an automation service can be published for others to consume.</li> </ul> <p>Approximate Duration: 2 hours</p>"},{"location":"watsonx%20Orchestrate/","title":"IBM watsonx Orchestrate","text":""},{"location":"watsonx%20Orchestrate/#overview","title":"Overview","text":"<p>IBM watsonx Orchestrate uses natural language processing to draw from a catalog of basic and advanced skills to execute your requests - in context and the correct order. No specialized training is needed. Get started in minutes using prebuilt skills designed for you and your needs. IT doesn't even have to get involved (unless they want to, of course).</p>"},{"location":"watsonx%20Orchestrate/#labs","title":"Labs","text":""},{"location":"watsonx%20Orchestrate/#track-2-developer-role-solution-implementation","title":"Track 2 - Developer Role / Solution Implementation","text":""},{"location":"watsonx%20Orchestrate/#lab-1-introduction-to-ibm-watsonx-orchestrate","title":"Lab 1. Introduction to IBM watsonx Orchestrate.","text":"<p>In this lab, you will build an IBM watsonx Orchestrate solution that re-imagines the quarterly promotions process. You will be re-using the existing IT assets to author an intelligent, AI-driven solution that pulls customer data from the system of records and creates targeted emails: Introduction to IBM watsonx Orchestrate Approximate Duration: 2-3 hours.</p>"},{"location":"watsonx%20Orchestrate/#lab-2-author-automation-with-ibm-watsonx-orchestrate-automation-builder","title":"Lab 2. Author Automation with IBM watsonx Orchestrate Automation Builder.","text":"<p>In this lab, you will build the Sales Campaign Approval Workflow, a component of the end user-facing quarterly promotions solution:  Author Automation with IBM watsonx Orchestrate Automation Builder</p> <p>Approximate Duration: 2-3 hours.</p>"}]}